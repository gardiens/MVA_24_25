{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACPNiuip-QVd"
      },
      "source": [
        "## **Practical work on SAR synthesis**\n",
        "\n",
        "### Florence TUPIN, Emanuele DALSASSO, Christophe KERVAZO\n",
        "\n",
        "Images of the practical work can be found on:\n",
        "https://perso.telecom-paristech.fr/tupin/TPSAR/\n",
        "\n",
        "You have:\n",
        "- Terrasar-X images of metric resolution on Grand canyon in Colorado.\n",
        "- Terrasar-X image of Paris\n",
        "- ERS-1 image of Lausanne\n",
        "\n",
        "Some useful functions are available in the file *mvalab.py*.\n",
        "\n",
        "### Name: Pierrick Bournez\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "To solve this practical session, answer the questions below. Then export the notebook with the answers using the menu option **File -> Download as -> Notebook (.ipynb)**. Then [submit the resulting file here](https://partage.imt.fr/index.php/s/74r8LMSzFz57iXt) by next week (deadline 30th of january).\n",
        "\n",
        "### Reading of images with TélécomParis format\n",
        "A useful function to read the images with Télécom-Paris format is *imz2mat*\n",
        "\n",
        "### First step: install needed packages\n",
        "In this and the following practical works, we are going to need\n",
        "- numpy: a fundamental package for scientific computing with Python\n",
        "- matplotlib: a Python 2D plotting library\n",
        "- scipy: library for numerical integration, interpolation, optimization, linear algebra and statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPskUOLCVZ9h"
      },
      "source": [
        "## **Introduction**\n",
        "### Complex images\n",
        "SAR images are usually complex data. Here are some useful `numpy` functions:\n",
        "- to take the conjugate: `np.conj`\n",
        "- to take the absolute value: `np.abs`\n",
        "- to take the real part: `np.real`\n",
        "- to take the imaginary part: `np.imag`\n",
        "- yo take the phase: `np.angle`. Value is between −π and +π.\n",
        "\n",
        "\n",
        "### Fourir transfrom of an image\n",
        "\n",
        "Python computes the Fourier transform of a 2D signal (matrix  Z) thanks to the package `scipy.fftpack`.\n",
        "- `scipy.fftpack.fft2` is the basic procedure. From a real image (2D array of real numbers), it returns a matrix of complex numbers.\n",
        "Be careful, the spectrum is given between 0 and 1 (in normalized frequency. To convert it between -0.5 and 0.5, you have to use `scipy.fftpack.fftshift` to center the spectrum.\n",
        "- `scipy.fftpack.ifft2` gives the 2D inverse Fourier transform.\n",
        "Be careful `scipy.fftpack.ifft2` usually gives a result with complex values even if the enter is a real matrix.\n",
        "- Do not forget that a spectrum is complex values. To visualize it,`np.abs` transforms a complex matrix to a real matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEwkUSWA-QVk"
      },
      "source": [
        "### Import the libraries and packages we are going to use\n",
        "The following cell imports all that is going to be necessary for the practical work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QLGMPF6LdTOG",
        "outputId": "4f8d1202-4cbb-4bcb-e1d9-ac117f9a70d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-24 14:28:09--  https://perso.telecom-paristech.fr/tupin/TPSAR/mvalab_v2.py\n",
            "Resolving perso.telecom-paristech.fr (perso.telecom-paristech.fr)... 137.194.22.227, 2a04:8ec0:0:a::89c2:16e3\n",
            "Connecting to perso.telecom-paristech.fr (perso.telecom-paristech.fr)|137.194.22.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68077 (66K) [text/x-python]\n",
            "Saving to: ‘mvalab_v2.py’\n",
            "\n",
            "mvalab_v2.py        100%[===================>]  66.48K   260KB/s    in 0.3s    \n",
            "\n",
            "2025-01-24 14:28:11 (260 KB/s) - ‘mvalab_v2.py’ saved [68077/68077]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://perso.telecom-paristech.fr/tupin/TPSAR/mvalab_v2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3SQWic4x-QVm"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import scipy as spy\n",
        "import scipy.fftpack\n",
        "import scipy.signal\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import mvalab_v2 as mvalab\n",
        "from urllib.request import urlopen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA-5vXjO-QVs"
      },
      "source": [
        "### SAR Images\n",
        "To read an image use {mvalab.imz2mat} with input parameter the image name (or url).\n",
        "It returns a list with a table of complex numbers, the number of columns and the number of lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-MZeANUZ-QVt",
        "outputId": "c814bbfc-bf7b-4327-f480-5309211c8f45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imz2mat : version janvier 2018.  Fichier à ouvrir : https://perso.telecom-paristech.fr/tupin/TPSAR/imagesbase/coloradoDP.CXF\n",
            "Nom compatible url\n",
            "Nom compatible url\n",
            "Complex float, Fichiers PC\n",
            "INFO - reading header/dim : https://perso.telecom-paristech.fr/tupin/TPSAR/imagesbase/coloradoDP.dim\n",
            "lecture .dim OK -> largeur:2048 hauteur:2048 profondeur:1\n",
            "Debug 2 4 2048\n",
            "4 2048 <f\n",
            "2048\n",
            "2048\n"
          ]
        }
      ],
      "source": [
        "url='https://perso.telecom-paristech.fr/tupin/TPSAR/imagesbase/'\n",
        "\n",
        "image='coloradoDP.CXF'\n",
        "imagesar=mvalab.imz2mat(url+image)\n",
        "tableauimage=imagesar[0]\n",
        "ncol=imagesar[1]\n",
        "nlig=imagesar[2]\n",
        "print(ncol)\n",
        "print(nlig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUyYcTY7-QVx"
      },
      "source": [
        "### Visualizing SAR data\n",
        "Visualize the amplitude and phase of the complex backscattered electro-magnetic field\n",
        "on Grand Canyon image.\n",
        "When just using imshow the full dynamic of the image is linearly converted to [0,255].\n",
        "When using mvalab.visusar, a threshold is defined threshold = mean(image)+k.standard_deviation(image)\n",
        "to use only the values between 0 and the threshold (values above the threshold are saturated at 255).\n",
        "A usual value of k is 3 (default value).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2H7tqvEs-QVx",
        "outputId": "00e12aae-988e-45a6-f379-c556d98fc6fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-4-8db1f47d01e5>, line 10)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-8db1f47d01e5>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    k =\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "\n",
        "plt.rcParams['figure.figsize'] = [9, 9]\n",
        "#visualization of amplitude data\n",
        "#to be completed\n",
        "plt.figure(figsize=[9,9])\n",
        "#plt.imshow(,'gray')\n",
        "plt.imshow(np.abs(tableauimage),'gray')\n",
        "\n",
        "#mvalab.visusar uses a threshold th=mean+ksigma to stretch the dynamic\n",
        "#two inpu parameters : table of pixels (absolute value) and k value to define the threshold\n",
        "k = 3\n",
        "mvalab.visusar(,k) #to complete - with thresholding\n",
        "\n",
        "#visualization of phase data\n",
        "plt.rcParams['figure.figsize'] = [9, 9]\n",
        "#to be completed\n",
        "plt.imshow()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyriSO7OpStq"
      },
      "source": [
        "### Question 1.a\n",
        "Explain what you see in the different images of Colorado acquisition and the role of the $k$ value.\n",
        "Give an interpretation of the amplitude image (which areas do you recognize)\n",
        "and of the phase image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj3_24Frpgzn"
      },
      "source": [
        "### Answer 1.a\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYgsn48p-QV1"
      },
      "source": [
        "# **Part 1: Analysis of a SAR image**\n",
        "In this part we will use an image of TerraSAR-X sensor (metric resolution) of Paris.\n",
        "Check that you recognize the main buildings on this image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gSU9xEv-QV2"
      },
      "outputs": [],
      "source": [
        "url='https://perso.telecom-paristech.fr/tupin/TPSAR/paris/'\n",
        "\n",
        "image='Eiffel.CXF'\n",
        "tabimage=mvalab.imz2mat(url+image)\n",
        "ncol=tabimage[1]\n",
        "nlig=tabimage[2]\n",
        "\n",
        "tabimage_ = tabimage[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrZ9BoEz-QV6"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [13, 13]\n",
        "mvalab.visusar(tabimage_)\n",
        "mvalab.visusar(np.angle(tabimage_)+math.pi,0.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxSPO_mmqEqW"
      },
      "source": [
        "### Analysis of a subpart of the image\n",
        "Choose a sub-part of the image and visualize the amplitude image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpal1A3tp5tn"
      },
      "outputs": [],
      "source": [
        "#to be completed\n",
        "tabimage_crop = tabimage_[200:800,1150:1750]\n",
        "mvalab.visusar(tabimage_crop)\n",
        "\n",
        "#tabimage_crop = tabimage_[]\n",
        "#mvalab.visusar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccRgl-xMqNIt"
      },
      "source": [
        "### Question 1.b\n",
        "\n",
        "Explain where is the sensor relatively to the scene.\n",
        "\n",
        "Explain the appearence of the following buildings in the amplitude image : Eiffel Tower, Maison de la radio, Pont de Bir-Hakeim (you can use a [satellite optic image on googlemaps](https://www.google.com/maps/place/Eiffel+Tower/@48.851143,2.2797819,447m/data=!3m1!1e3!4m5!3m4!1s0x47e66e2964e34e2d:0x8ddca9ee380ef7e0!8m2!3d48.8583701!4d2.2944813) to help you).\n",
        "\n",
        "Explain the appearence of water and vegetated areas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ciDf1wzqOZt"
      },
      "source": [
        "### Answer 1.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjsZGJfZ-QV9"
      },
      "source": [
        "### Spectral analysis\n",
        "Plot the modulus of complex spectrum of the image and the modulus of the Fourier transform of the image taken in amplitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZZNqgPF-QV-"
      },
      "outputs": [],
      "source": [
        "# SPECTRAL ANALYSIS mvalab.visusarspectre: plot the image and its Fourier spectrum\n",
        "# for the image taken in modulus\n",
        "mvalab.visusarspectre()\n",
        "# for the complex image\n",
        "mvalab.visusarspectre()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRbDtNwUrbBn"
      },
      "source": [
        "### Question 1.c\n",
        "\n",
        "Explain what you see in the Fourier spectrum of the complex image. How are the two axis related to the SAR image synthesis ?\n",
        "\n",
        "Explain what you see in the Fourier spectrum of the amplitude image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o57Jr9VM-QWT"
      },
      "source": [
        "# **Part 2: SAR synthesis using SAR RAW data**\n",
        "To study the SAR synthesis we will use a ERS-1 SAR image which is provided by ESA in \"raw\" format.\n",
        "It means that it corresponds to the image before the chirp compression in range and before the synthetic aperture in the azimuth direction.\n",
        "What do you see on the raw data ? Can you recognize the area ? (It corresponds to [Leman Lake and Lausanne](https://www.google.com/maps/place/Lausanne,+Switzerland/@46.5284586,6.5824552,12z/data=!3m1!4b1!4m5!3m4!1s0x478c293ecd89a7e5:0xeb173fc9cae2ee5e!8m2!3d46.5196535!4d6.6322734))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ida_AxB-QWU"
      },
      "outputs": [],
      "source": [
        "url='https://perso.telecom-paristech.fr/tupin/TPSAR/imagesbase/'\n",
        "image='lausanneED.CXF'\n",
        "\n",
        "tabimage=mvalab.imz2mat(url+image)\n",
        "ncol=tabimage[1]\n",
        "nlig=tabimage[2]\n",
        "\n",
        "mvalab.visusar(tabimage[0])\n",
        "mvalab.visusar(np.angle(tabimage[0])+math.pi,0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-ratUDe-QWX"
      },
      "outputs": [],
      "source": [
        "# visualization of the Fourier spectrum of the complex image\n",
        "mvalab.visusarspectre()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMvgKU_tsfpD"
      },
      "source": [
        "### Question 2.a\n",
        "Where is the lake on this image ? How can we localize Lausanne city ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sau-YGkCsh9w"
      },
      "source": [
        "### Answer 2.a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXMB9QuT-QWb"
      },
      "source": [
        "# **Range compression (fast time)**\n",
        "The raw data need to be compressed along the range direction using a matched filter.\n",
        "The chirp is given and corresponds to the emitted wave of ERS sensor. The matched filter is a temporal convolution\n",
        "or equivalently a multiplication of the Fourier transforms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO7GxRGU-QWc"
      },
      "outputs": [],
      "source": [
        "# the chirp of ERS-1 is given in the specification of ESA\n",
        "sigchirp=mvalab.chirp_ers()   #Warning only 703 points to encode the chirp\n",
        "nsig=len(sigchirp)\n",
        "K=4.1889e+11\n",
        "\n",
        "#display of the chirp (real and imaginary parts)\n",
        "plt.rcParams['figure.figsize'] = [6, 6]\n",
        "plt.figure()\n",
        "plt.subplot(211)\n",
        "plt.plot(np.real(sigchirp))\n",
        "plt.subplot(212)\n",
        "plt.plot(np.imag(sigchirp))\n",
        "plt.show()\n",
        "\n",
        "# display of the Fouriertransform of the chirp\n",
        "##%%%\n",
        "lignechirp=np.zeros(ncol,dtype=complex)\n",
        "lignechirp[0:nsig]=sigchirp # padding\n",
        "tfchirp=scipy.fftpack.fft(lignechirp)\n",
        "plt.figure()\n",
        "plt.plot(np.abs(scipy.fftpack.fftshift(tfchirp)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK7IYYjjPTuI"
      },
      "outputs": [],
      "source": [
        "# range compression done in the Fourier transform line by line by FT multiplication\n",
        "#to be completed\n",
        "fft1tabimage=scipy.fftpack.fft(tabimage[0],axis=1)\n",
        "fft2tabimage=np.zeros((nlig,ncol),dtype=complex)\n",
        "for iut in range(nlig):\n",
        "    fft2tabimage[iut,:]= # To complete\n",
        "\n",
        "newimage=scipy.fftpack.ifft(fft2tabimage,axis=1)\n",
        "mvalab.visusarspectre(newimage,u'Chirp compression step')\n",
        "\n",
        "#########################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l203X-IwnTV"
      },
      "source": [
        "### Question 2.b\n",
        "What is the effect of the chirp convolution in the range direction ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J-q8agOwpc1"
      },
      "source": [
        "### Answer 2.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plLO8TX2-QWh"
      },
      "source": [
        "# **Azimuth compression (slow time) - approximation**\n",
        "We are now interested in the synthetic aperture computation in the azimuth direction. Two different compression techniques will be analysed in the following cells.\n",
        "First, the synthesis is done very approximately by just adding the complex signals in column (azimuth) without doing the phase correction.\n",
        "Compute a simple column convolution with a chosen size (30, 50 70 pixels for instance)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voFSFxH9-QWi"
      },
      "outputs": [],
      "source": [
        "#########################################################################\n",
        "##############  SYNTHESIS - approximation\n",
        "############## constant kernel\n",
        "\n",
        "#choose a size for the window to do the azimuth processing\n",
        "largeur=50\n",
        "#create a mask of values 1 with np.ones()\n",
        "masque=np.ones(largeur)\n",
        "newimage_step1=np.zeros( (nlig,ncol),dtype=complex)\n",
        "#do the convolution with the masque in azimuth direction - to keep the same size use mode='same'\n",
        "for jut in range(ncol):\n",
        "    newimage_step1[:,jut]= # To complete\n",
        "montitre=u'Size of the uniform kernel : %d'%largeur\n",
        "mvalab.visusarspectre(,montitre) # To complete\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob0uBCIzwvKG"
      },
      "source": [
        "### Question 2.c\n",
        "\n",
        "What is the effect of the constant kernel convolution in the range direction ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxuwW36wyod"
      },
      "source": [
        "### Answer 2.c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W080Ob7m-QWk"
      },
      "source": [
        "# **Azimuth compression (slow time) - synthetic aperture**\n",
        "In this part, the real aperture synthesis is done.\n",
        "To do so, first the distance from the sensor to each pixel considered in the window (in azimuth) is computed.\n",
        "This distance is then used to correct the phase contribution of each pixel ($\\phi=\\frac{4\\pi R}{\\lambda}$).\n",
        "The associated instant frequency is given by $f_d=\\frac{1}{2\\pi}\\frac{d\\phi}{dt}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9celEfugEae"
      },
      "outputs": [],
      "source": [
        "##############  SYNTHESIS - ERS-1 PARAMETERS (given by ESA)\n",
        "##############  Modulated window\n",
        "# ERS-1 parameters to process raw data\n",
        "#  Program using a fixed length of synthesis (=fixed number of samples - no range migration correction)\n",
        "longueurdonde = 3./53. # en cm\n",
        "print(longueurdonde)\n",
        "prf=1679.902 #theoretical PRF (Pulse Repetition Frequency) of ERS-1\n",
        "vitessesatel=7460 # speed of the satellite in m/s\n",
        "#distance from the sensor to the earth for the incidence angle of the considered area\n",
        "#it corresponds to the distance between the sensor and the closest point in the swath\n",
        "#(cpa closest point of approach)\n",
        "dsatel=845000;  # for 24 degrees of incidence angle (considered as constant in the swath here)\n",
        "#sampling in position for the sensor position in the flight direction\n",
        "#deltay is the distance between two sensor positions sending a pulse= speed/pulse_frequency\n",
        "deltay=vitessesatel/prf;\n",
        "print(deltay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUPnHSPEg5UA"
      },
      "outputs": [],
      "source": [
        "#############  SYNTHESIS - COMPUTATION OH THE MATCHED FILTER\n",
        "##############  Modulated window to do the azimuth focalization\n",
        "#chosen number of points for the synthetic aperture synthesis\n",
        "largeur=800\n",
        "NN=int(0.5*largeur)\n",
        "# computation of the phase ramp and complex exponential\n",
        "# replacing the \"natural window\" with weight 1 of the previous section\n",
        "#\n",
        "# sensor positions around 0 (-400 positions before, 400 positions after in meters)\n",
        "tabpos=deltay*np.linspace(-NN,NN,largeur) #returns 800 evenly spaced points between -400 and 400\n",
        "#tab_cpa contains a table of the cpa distances\n",
        "tab_cpa=dsatel*np.ones(largeur)\n",
        "#compute in tabR the distance from the point to the sensor\n",
        "#for the sensor positions in tabpos using Pythagore\n",
        "tabR=   #To be completed\n",
        "\n",
        "# compute in tabR_diff the difference between tabR and tab_cpa corresponding to the distance difference\n",
        "#compared to the closest position\n",
        "tabR_diff=  #To be completed\n",
        "\n",
        "# check you obtain a quadratic contribution for tabR_diff as seen in course\n",
        "plt.figure()\n",
        "plt.plot()\n",
        "plt.show()\n",
        "\n",
        "# convert the distance to the sensor in a phase contribution using phi=(4piR)/lambda\n",
        "tab_phi =        #To be completed\n",
        "#convert the phase in the complex exponential contribution (phase ramp)\n",
        "tab_ramp =      #To be completed\n",
        "\n",
        "# check if the instant frequency is linear using np.diff for the differentiation\n",
        "fd =     #To be completed - instant frequency\n",
        "plt.figure()\n",
        "plt.subplot(311)\n",
        "plt.plot(np.real(tab_ramp))\n",
        "plt.subplot(312)\n",
        "plt.plot(np.imag(tab_ramp))\n",
        "plt.subplot(313)\n",
        "plt.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E47J5QCL-QWl"
      },
      "outputs": [],
      "source": [
        "\n",
        "##############  SYNTHESIS - applying the convolution filter\n",
        "##############  Modulated window\n",
        "######################### Warning : use the image newimage after chirp compression in distance\n",
        "\n",
        "newimage_foc=np.zeros( (nlig,ncol),dtype=complex)\n",
        "#do the matched filter by azimuth convolution with mode='same'\n",
        "for jut in range(ncol):\n",
        "    newimage_foc[:,jut]=\n",
        "montitre=u'Number of samples used to do the synthetic aperture : %d'%largeur\n",
        "# visualization de l'image focalisée et de son spectre\n",
        "mvalab.visusarspectre(, montitre )\n",
        "#display the image after synthetic aperture computation\n",
        "mvalab.visusar(newimage_foc)\n",
        "#disaply the original image for comparison\n",
        "mvalab.visusar(tabimage[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f9Gnd6pxf-v"
      },
      "source": [
        "### Question 2.d\n",
        "Compare the synthesized image with the mean kernel and the one taking into account the phase variation due to the distance. Compare the image obtained after synthesis in range and azimuth direction and the original image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp0IFc_exiDV"
      },
      "source": [
        "### Answer 2.d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yspMzPnD-QWq"
      },
      "source": [
        "# **Azimuth multi_looking**\n",
        "The size of the SLC pixel for ERS-1 are 3m in azimuth and 12m in range.\n",
        "To obtain square pixels, a simple processing is averaging amplitude values\n",
        "and then do an undersampling with a factor of 4.\n",
        "It is even better to do the averaging on intensity values (square of the modulus)\n",
        "and then take the square root.\n",
        "Do you recognize Lausanne on this image ? (use google maps to have an optical view)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raX4wXGF-QWs"
      },
      "outputs": [],
      "source": [
        "#define a vertical mask to do the convolution\n",
        "masque_vert=\n",
        "#do the convolution on the intensity image obtained by z.z* (=|z|²)\n",
        "ml_int=\n",
        "#do the sub-sampling to obtain square pixels with improved radiometry\n",
        "ml_int_sub=ml_int[::4,:]\n",
        "plt.rcParams['figure.figsize'] = [20, 5]\n",
        "#take the square root of the intensity to have an amplitude image (proportional to |z|)\n",
        "mvalab.visusar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKE0EEe_xre4"
      },
      "source": [
        "### Question 2.e\n",
        "What is the effect of multi-looking ? Is this image well oriented compared to a map ? Use the Lac de Bret to check this point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFKUQpjJxufR"
      },
      "source": [
        "### Answer 2.e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7eam4lm-QWv"
      },
      "source": [
        "# **Example of a High Resolution image**\n",
        "The obtained image after chirp compression and synthetic aperture processing is still difficult to understand because of the coarse resolution of ERS.\n",
        "To illustrate these processing on a more impressive case, you can apply the following functions. Basically it is the same as before, but with dedicated chirp and distance computations.\n",
        "WARNING: the range and azimuth are not the usual one (vertical = range direction, horizontal = azimuth direction)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeYPdUNj-QW4"
      },
      "outputs": [],
      "source": [
        "#example on the aerial image\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1vR2m7Lb2aI6Dhak4u9eR2ZPGYhasmCO5',\n",
        "                                    dest_path='./HighRes.zip',\n",
        "                                    unzip=True)\n",
        "import sys\n",
        "sys.path.append('./HighRes/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShZvCN54VZ9y"
      },
      "outputs": [],
      "source": [
        "# mvalab.synthese_range reads the matrix containing the raw data and the system\n",
        "#parameters and compute the synthesis in the range direction\n",
        "raw_data, range_compressed_data = mvalab.synthese_range('./HighRes/data2.mat')\n",
        "mvalab.visusar(raw_data)\n",
        "mvalab.visusar(range_compressed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6X4xPs9aVZ9z"
      },
      "outputs": [],
      "source": [
        "#mvalab.synthese_azimuth takes the range compressed image and does the azimuth compression step\n",
        "compressed_data = mvalab.synthese_azimuth(range_compressed_data, './HighRes/data2.mat')\n",
        "mvalab.visusar(compressed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6XJtwFN-QW7"
      },
      "source": [
        "# **Part 3: Sub aperture analysis** (OPTIONNAL PART)\n",
        "Let us go back to the understanding of the complex spectrum information.\n",
        "Indeed, both axes of the complex Fourier transform of a Single look Complex image are related to SAR synthesis: the range (horizontal) axis is related to the chirp frequencies, and the azimuth (vertical) axis is related to the sensor positions during the Synthetic Aperture synthesis.\n",
        "The target is observed by the radar for a time corresponding to the observation time. Therefore, each frequency carries information about the observed target. We can see this in the following examples, where we are going to consider only a sub part of the synthetic aperture of the radar:\n",
        "- in the first example, we use a sub-set of the samples to compute the synthetic aperture (half of the samples either before of after the closest point position). It means that we do the azimuth compression using only half part of the filter, see code). We can compute two images, each one using only half of the \"seen\" samples during the acquisition.\n",
        "- in the second example, we use only the synthesized image and we process the complex Fourier spectrum. In the Fourier spectrum, we select in azimuth (vertical positions in the spectrum) a sub-window called sub-aperture, we do zero-padding for the remaining part of the spectrum and compute the inverse Fourier transform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZom_j0f-QW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "###################################################################################\n",
        "#################### sub-aperture in the synthesis step\n",
        "####################\n",
        "#%%\n",
        "\n",
        "largeur=320\n",
        "tabresulSO=[]\n",
        "\n",
        "NN=int(0.5*largeur)\n",
        "tabposbase=deltay*np.linspace(-NN,NN,largeur)\n",
        "tabpos=deltay*np.linspace(-NN,NN,largeur)\n",
        "tabR=dsatel*np.ones(largeur);\n",
        "tabR2=tabR*tabR+tabpos*tabpos\n",
        "tabR2=np.sqrt(tabR2)-tabR;\n",
        "tabpha =2*( 2*math.pi/longueurdonde*tabR2);  # un 2 pour l'AR\n",
        "tabphabase = np.exp(1j*tabpha);\n",
        "\n",
        "#in the following two subparts of the aperture are used to compute two images\n",
        "tabselstart=[0,NN]\n",
        "tabselstop=[NN,2*NN]\n",
        "for iut in range(2):\n",
        "    tabpha=np.copy(tabphabase)\n",
        "    tabpha[tabselstart[iut]:tabselstop[iut]]=0.\n",
        "    newimage_step2=np.zeros( (nlig,ncol),dtype=complex)\n",
        "    for jut in range(ncol):\n",
        "        newimage_step2[:,jut]= spy.signal.convolve(newimage[:,jut],tabpha,mode='same')\n",
        "    montitre=u'Size of the selected samples : (%d,%d)'%(tabselstart[iut],tabselstop[iut])\n",
        "    mvalab.visusarspectre(newimage_step2, montitre )\n",
        "    tabresulSO.append(newimage_step2)\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [21, 21]\n",
        "plt.figure()\n",
        "plt.subplot(121)\n",
        "mvalab.visusarZ(tabresulSO[0])\n",
        "plt.subplot(122)\n",
        "mvalab.visusarZ(tabresulSO[1])\n",
        "plt.show()\n",
        "\n",
        "##################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux7a1IfS-QXB"
      },
      "outputs": [],
      "source": [
        "\n",
        "###################################################################################\n",
        "####################  sub-aperture using the spectrum of the synthesized complex image\n",
        "####################\n",
        "#%%\n",
        "\n",
        "mvalab.visusarspectre(newimage_foc)\n",
        "imafft=scipy.fftpack.fftshift(scipy.fftpack.fft2(newimage_foc))\n",
        "mvalab.visusar(imafft)\n",
        "#%%\n",
        "\n",
        "imafiltrefft=np.zeros((nlig,ncol),dtype=complex)\n",
        "imafiltrefft[int(nlig/2)-largeur:int(nlig/2),:]=imafft[int(nlig/2)-largeur:int(nlig/2),:]\n",
        "#imafiltrefft[1024:1300,:]=imafft[1024:1300,:]\n",
        "\n",
        "tabresulsousbande=scipy.fftpack.ifft2(scipy.fftpack.fftshift(imafiltrefft))\n",
        "mvalab.visusarspectre(tabresulsousbande)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRUosoxmW7T_"
      },
      "source": [
        "## Question 3.a\n",
        "Compare the different results obtained using sub-apertures either on the raw data or on the synthetized image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1WRbT25XJ79"
      },
      "source": [
        "## Answer 3.a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxILreKO-QXF"
      },
      "source": [
        "# **Sub-aperture on TerraSAR-X image of Paris**\n",
        "To understand the effects of sub-aperture decomposition, select a sub-aperture and synthesize different images for different selected bands. Observe some bright scatterers and see how they vary in the different sub-parture selections.\n",
        "How can you explain the variations of the backscattered signals for the different sub-apertures ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMvRoitj-QXG"
      },
      "outputs": [],
      "source": [
        "###################################################################################\n",
        "####################  sub-aperture using the spectrum of the synthesized image - PARIS\n",
        "####################\n",
        "#%%\n",
        "\n",
        "mvalab.visusarspectre(tabimage_,'original image')\n",
        "imafft=scipy.fftpack.fftshift(scipy.fftpack.fft2(tabimage_))\n",
        "#%%\n",
        "#take other values for the selected frequencies and study some specific strong targets\n",
        "f1 = 1000\n",
        "df = 200\n",
        "imafiltrefft=np.zeros((nlig,ncol),dtype=complex)\n",
        "imafiltrefft[f1:f1+df,:]=imafft[f1:f1+df,:]\n",
        "\n",
        "tabresulsousbande=scipy.fftpack.ifft2(scipy.fftpack.fftshift(imafiltrefft))\n",
        "mvalab.visusarspectre(tabresulsousbande,'sub-aperture filtered image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkHvP6yTySJj"
      },
      "source": [
        "### Question 3.b\n",
        "Choose different values for $f_1$ and $d_f$. Comment the images you see: what is the influence of these parameters on the type of reflection you see and on the resolution?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Ln2DCIzBJ9"
      },
      "source": [
        "### Answer 3.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6D1tFtP-QXJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}