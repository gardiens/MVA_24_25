{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project guidé de segmentation des vaisseaux\n",
    "\n",
    "- A faire en monome ou binôme (pas plus de 2 étudiants)\n",
    "- Indiquez NOM-prénom des 1 ou 2 personnes impliquées \n",
    "- La soumission doit se faire sur EDUNAO\n",
    "\n",
    "Pierrick Bournez Antoine Viaille\n",
    "Hugues Talbot Février 2025\n",
    "\n",
    "## Ajout: Conclusion des résultats\n",
    "AJOUTER A La FIN\n",
    "|       Méthode       | Partie | score Dice moyen | min | max | std |\n",
    "|:-------------------|:----------------:|:----------------:|:----------------:|:----------------:|:----------------:|\n",
    "|  Seuillage simple 0.05  |        2       |        0.67      |        0.54       |        0.74       |        0.06       |\n",
    "|  Seuillage Otsu % image |        2       |        0.65       |        0.38       |        0.75       |        0.10       |\n",
    "| $\\{\\text{seuillage}, \\text{taille disque}\\}$ optimisé |        3.1       |        0.67       |        0.58       |        0.74       |        0.05       |\n",
    "| **Amélioration débruitage** | 3.2 | \n",
    "|  non local mean (nlm) |        3.2       |        0.66       |        0.47       |        0.76       |        0.08       |\n",
    "|  nlm paramètres opt. |        3.2       |        0.67       |        0.48       |        0.76       |        0.08       |\n",
    "|  mm denoising |        3.2       |        0.69       |        0.53      |        0.76       |        0.06       |\n",
    "| **Approches segmentation** | 3.3-3.5 | \n",
    "| approche par gradient | 3.3 | 0.48 | 0.41 | 0.53 | 0.04 | \n",
    "| approche avec higra | 3.4 | 0.68 | 0.55 | 0.73 | 0.05 |  \n",
    "| filtre de Frangi | 3.5 | 0.88 |0.86 | 0.89 | 0.006 |\n",
    "| filtre de Sato | 3.5 | **0.98** | 0.975 | 0.98 | 0.001 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ## La bonne façon d'installer cv2, à ne réaliser que si besoin\n",
    "\n",
    "# !pip3 uninstall opencv-contrib-python opencv-python\n",
    "# !pip3 install opencv-contrib-python\n",
    "# !pip3 install imagecodecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ne pas executer à l'intérieur de Visual Studio Code\n",
    "# %matplotlib notebook\n",
    "## A l'intérieur de Google Colab, utiliser plutôt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet guidé, segmentation de vaisseaux sanguins\n",
    "\n",
    "Les vaisseaux sanguins sont très difficiles à identifier et segmenter sur des images car se sont des objets \"fins\" : ils ont une orientation locale privilégiée, et deviennent généralement plus petit en diamètre que la résolution du capteur. Ils disparaissent donc progressivement dans le bruit de celui-ci.\n",
    "\n",
    "L'objectif de ce projet est de realiser une segmentation d'images de vaisseaux de fond d'oeil avec des performances acceptables par des moyens classiques, y compris la morphologie mathématique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import cv2\n",
    "import imageio.v2 as iio\n",
    "import imagecodecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To help viewing images\n",
    "\n",
    "## to view a single image\n",
    "def imview(image, cmap=\"gray\", interpolation=\"nearest\", figsize=(6, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image, cmap=cmap, interpolation=interpolation)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## to view several images at once\n",
    "def viewlist(images, cmap=\"gray\", figsize=(18, 6), titles=None):\n",
    "    plt.figure(figsize=(len(images) * 6, 6))\n",
    "    columns = len(images)\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, columns, i + 1)\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.axis(\"off\")\n",
    "        if titles is not None:\n",
    "            plt.title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaisseaux rétiniens\n",
    "\n",
    "Les images de fond d'oeil sont acquises en routine chez les ophtalmologues à chaque visite. On peut y déceler de nombreuses pathologies, celles affectant la rétine mais aussi d'autres telles l'hypertension arterielle ou le diabète, même à un stade peu développé. C'est une des rares modalités où il est relativement facile de déceler les vaisseaux capillaires.\n",
    "\n",
    "On utilise ici une petite base de donnée de 20 images. L'illustration des méthodes se fait sur l'une d'entre elles mais vous devez faire tourner vos methodes sur les 20 images. La base comprend les images de fond d'oeil, un masque de la zone d'acquisition et un masque binaire des vaisseaux segmentés à la main par un spécialiste. On cherche à s'approcher de la qualité de la segmentation manuelle.\n",
    "\n",
    "Même dans le cas où on souhaiterait utiliser une approche par apprentissage, il est essentiel de réaliser une normalisation des images pour éviter les variations de couleur, illumination, niveau de bruit intenpestifs.\n",
    "\n",
    "Voici une stratégie générale:\n",
    "\n",
    "- Trouver le masque de la zone d'acquisition, car en pratique clinique, celui-ci n'est pas donné. \n",
    "- Rehausser l'apparence des vaisseaux, avec par exemple un filtre médian et/ou un top-hat noir (voir ci-dessous) \n",
    "- Réduire le bruit sans détruire les vaisseaux. Des filtres connectifs pourraient être utiles.\n",
    "- Trouver un seuillage automatique\n",
    "- Optimiser les paramètres de ces approches pour s'approcher le plus possible du résultat de segmentation manuel.\n",
    "\n",
    "Essayez vos stratégiques sur 1-3 images, testez sur la base toute entière de 20 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lecture d'une image\n",
    "img1 = iio.imread(\"Eye_fundus/images/21_training.tif\")\n",
    "## masque d'acquisition\n",
    "gtmask1 = iio.imread(\"Eye_fundus/mask/21_training_mask.gif\")\n",
    "## annotation manuelle du masque des vaisseaux. Notez qu'il n'est pas parfait mais vous allez vous rendre compte que c'est difficile de s'en approcher.\n",
    "manual1 = iio.imread(\"Eye_fundus/1st_manual/21_manual1.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewlist((img1, gtmask1, manual1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Segmentation du masque binaire\n",
    "\n",
    "Ça devrait être assez facile car le contraste est assez net...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en niveaux de gris\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "imgg1 = rgb2gray(img1)\n",
    "print(\"Min = \", np.min(imgg1), \"Max = \", np.max(imgg1))\n",
    "\n",
    "imview(imgg1)\n",
    "\n",
    "\n",
    "binmask1 = imgg1 > 0.1\n",
    "imview(binmask1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure de la qualité de la segmentation\n",
    "\n",
    "La qualité d'une segmentation est souvent donnée par la pseudo-métrique de Dice, qui vaut 0 si une segmentation de référence et celle proposée n'ont rien en commun, et 1 si elles sont identiques.\n",
    "\n",
    "Cette métrique est la même que la métrique F1 d'une matrice de confusion.\n",
    "\n",
    "$$ \n",
    "\\begin{matrix}\n",
    "                & \\text{True} & \\text{False} \\\\\n",
    "\\text{Positive} &     TP      & FP           \\\\\n",
    "\\text{Negative} &     FN      & TN           \\\\\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Les vérité de terrain sont en colonne et les estimations en ligne\n",
    "\n",
    "Le score F1 ou la métrique de Dice sont données par la formule\n",
    "$$\n",
    "Dice(A,B) = \\frac{2 TP}{TP+FP+FN}\n",
    "$$\n",
    "\n",
    "On note que les vrais négatifs ne sont pas utilisés. C'est normal, car dans une segmentation le plus souvent le fond est beaucoup plus grand que la forme en surface. Utiliser les vrais négatifs dans une mesure de précision par exemple donnerait des résultats faussement optimistes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(im1, im2):\n",
    "    \"\"\"\n",
    "    Computes the Dice coefficient, a measure of set similarity.\n",
    "    Parameters\n",
    "    ----------\n",
    "    im1 : array-like, bool\n",
    "        Any array of arbitrary size. If not boolean, will be converted.\n",
    "    im2 : array-like, bool\n",
    "        Any other array of identical size. If not boolean, will be converted.\n",
    "    Returns\n",
    "    -------\n",
    "    dice : float\n",
    "        Dice coefficient as a float on range [0,1].\n",
    "        Maximum similarity = 1\n",
    "        No similarity = 0\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The order of inputs for `dice` is irrelevant. The result will be\n",
    "    identical if `im1` and `im2` are switched.\n",
    "    \"\"\"\n",
    "    im1 = np.asarray(im1).astype(bool)\n",
    "    im2 = np.asarray(im2).astype(bool)\n",
    "\n",
    "    if im1.shape != im2.shape:\n",
    "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "\n",
    "    return 2.0 * intersection.sum() / (im1.sum() + im2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Qualité de la segmentation réalisée\n",
    "\n",
    "print(\"Quality of the mask segmentation:\", dice(gtmask1, binmask1))\n",
    "\n",
    "## anything over 99% is pretty much indistinguishable from the ground truth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 : vérifier et si nécessaire améliorez la qualité de la segmentation du masque sur toute la base de donnée\n",
    "\n",
    "Reportez le Dice moyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 1: Votre code ici\n",
    "dices_mask = []\n",
    "for i in range(21, 41):  # the data only lies from 21 to 40\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    imgg = rgb2gray(img)\n",
    "    binmask = imgg > 0.1\n",
    "    dices_mask.append(dice(gtmask, binmask))\n",
    "\n",
    "print(\n",
    "    \"Average Dice Mask value: \",\n",
    "    np.mean(dices_mask),\n",
    "    f\" on the  {len(dices_mask)} images.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__answer__: On a un Dice Mask moyen de 0.99 ce qui est très bien, on ne doit pas à priori améliorer la qualité de la segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Preprocessing de l'image de fond d'oeil\n",
    "\n",
    "On pourra utiliser le masque segmenter pour réduire les effets de bord.\n",
    "\n",
    "Première idée simple: un top-hat noir. D'après le cours de morphologie mathématique, une fermerture $\\varphi_B$ avec un élément structurant $B$ est extensive.\n",
    "On calcule $BTH$ de la façon suivante\n",
    "\n",
    "$$\n",
    "BTH(I) = \\varphi_B(I) - I\n",
    "$$\n",
    "\n",
    "Ce résidu est donc une image positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import closing, disk\n",
    "\n",
    "imgclo1 = closing(imgg1, disk(11))\n",
    "\n",
    "imview(imgclo1)\n",
    "\n",
    "## black top hat\n",
    "\n",
    "bth1 = imgclo1 - imgg1\n",
    "imview(bth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seuillage simpliste\n",
    "\n",
    "vessels1 = (bth1 > 0.05) * binmask1\n",
    "viewlist((binmask1, vessels1, manual1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mesure des performances de cette approche\n",
    "\n",
    "print(\"Vessel segmentation quality\", dice(manual1, vessels1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: automatiser et faire tourner cette approche sur la base de 20 images\n",
    "\n",
    "Le seuillage est manuel, mais un seuillage automatique serait sans doute meilleur. \n",
    "\n",
    "voir par exemple [cette page](https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_thresholding.html), qui fait partie de la documentation de Scikit-image\n",
    "\n",
    "Rapportez le Dice moyen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 2: Votre code pour la segmentation des vaisseaux sur la base de données.\n",
    "\n",
    "\n",
    "dices_ostu = []\n",
    "dices_004 = []\n",
    "for i in range(21, 41):\n",
    "    # Lecture des images\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual1 = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    imgg = rgb2gray(img)\n",
    "\n",
    "    # masque / ouverture\n",
    "    binmask = imgg > 0.1\n",
    "    imgclo = closing(imgg, disk(11))\n",
    "    bth = imgclo - imgg\n",
    "\n",
    "    # seuillage\n",
    "    otsu_threshold = skimage.filters.threshold_otsu(bth * binmask)\n",
    "    vessels1 = (bth > otsu_threshold) * binmask\n",
    "    vessels2 = (bth > 0.04) * binmask\n",
    "\n",
    "    # affichage et dice\n",
    "    score_dice_otsu = dice(manual1, vessels1)\n",
    "    score_dice_004 = dice(manual1, vessels2)\n",
    "    dices_ostu.append(score_dice_otsu)\n",
    "    dices_004.append(score_dice_004)\n",
    "    print(\"------ Image \", i, f\" (dice Otsu {score_dice_otsu}) ------\")\n",
    "    viewlist(\n",
    "        (imgg, imgclo1, manual1, bth * binmask, vessels1, vessels2),\n",
    "        titles=[\n",
    "            \"GT Image\",\n",
    "            \"Ouverture\",\n",
    "            \"GT Manuel\",\n",
    "            \"Black top hat\",\n",
    "            f\"Seuillage Otsu {score_dice_otsu}\",\n",
    "            f\"Seuillage 0.04 {score_dice_004}\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "print(\n",
    "    f\" Dice Otsu moyen sur les {len(dices_ostu)} images:  {np.mean(dices_ostu)}. Le meilleur dice est de {np.max(dices_ostu)} sur l'image {np.argmax(dices_ostu) + 21}\"\n",
    ")\n",
    "print(\n",
    "    f\"min: {np.min(dices_ostu)}, max: {np.max(dices_ostu)}, std: {np.std(dices_ostu)}\"\n",
    ")\n",
    "print(\n",
    "    f\" Dice 0.04 moyen sur les {len(dices_004)} images:  {np.mean(dices_004)}. Le meilleur dice est de {np.max(dices_004)} sur l'image {np.argmax(dices_004) + 21}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices_004)}, max: {np.max(dices_004)}, std: {np.std(dices_004)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On remarque que le Seuillage d'Otsu n'est pas meilleur qu'un seuillage manuel. Il a en effet un score moyen de $0.65$ alors qu'un seuillage manuel de $0.04$ donne un score de $0.67$. Les méthodes ont la même moyenne, maximal mais l'estimateur manuel est plus consistent ( sa valeur minimal est 0.51 contre 0.37) On remarque que le seuillage d'Otsu garde du bruit autour des vaisseaux, donnant un résultat moins bon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the histogram of the black top hat image and Otsu threshold for image 25 and compute Dice score.\n",
    "img25 = iio.imread(\"Eye_fundus/images/25_training.tif\")\n",
    "gtmask25 = iio.imread(\"Eye_fundus/mask/25_training_mask.gif\")\n",
    "manual25 = iio.imread(\"Eye_fundus/1st_manual/25_manual1.gif\")\n",
    "imgg25 = rgb2gray(img25)\n",
    "binmask25 = imgg25 > 0.1\n",
    "imgclo25 = closing(imgg25, disk(11))\n",
    "bth25 = imgclo25 - imgg25\n",
    "otsu_threshold = skimage.filters.threshold_otsu(bth25 * binmask25)\n",
    "vessels25 = (bth25 > otsu_threshold) * binmask25\n",
    "viewlist(\n",
    "    (bth25, bth25 * binmask25, vessels25),\n",
    "    titles=[\"Black top hat\", \"bth*seuil\", \"Seuillage Otsu\"],\n",
    ")\n",
    "print(\"Dice score for image 25: \", dice(manual25, vessels25))\n",
    "\n",
    "# plot histogram of the black top hat image and Otsu threshold for image 25\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(bth25.flatten(), bins=256, range=(0, 1), density=True)\n",
    "plt.title(\"Histogramme\")\n",
    "plt.axvline(otsu_threshold, color=\"r\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Optionnel: améliorer votre score\n",
    "\n",
    "Les questions 1 et 2 sont les seules obligatoires. En option, vous pouvez tenter d'améliorer votre score moyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1: Ajout:  Optimisation du diamètre du disque et du seuillage \n",
    "On va optimiser les deux paramètres: diamètre du disque et seuil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_start = 31\n",
    "training_end = 41\n",
    "test_start = 21\n",
    "test_end = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting a heatmap of the combination of the sizes of disk and threshold values for all images\n",
    "from tqdm import tqdm\n",
    "\n",
    "dices = {}\n",
    "disk_sizes = np.arange(1, 17, 1)\n",
    "thresholds = np.arange(0.01, 0.25, 0.01)\n",
    "for disk_size in tqdm(disk_sizes):\n",
    "    for threshold in thresholds:\n",
    "        dices[(disk_size, threshold)] = []\n",
    "        for i in range(training_start, training_end):\n",
    "            img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "            gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "            manual1 = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "            imgg = rgb2gray(img)\n",
    "            binmask = imgg > 0.1\n",
    "            imgclo = closing(imgg, disk(disk_size))\n",
    "            bth = imgclo - imgg\n",
    "            vessels = (bth > threshold) * binmask\n",
    "            score_dice = dice(manual1, vessels)\n",
    "            dices[(disk_size, threshold)].append(score_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a choisi un disque de taille 16\n",
    "dices2 = {k: v for k, v in dices.items() if k[0] <= 16}\n",
    "dices_array = np.array(\n",
    "    [\n",
    "        [np.mean(dices2[(disk, threshold)]) for threshold in thresholds]\n",
    "        for disk in disk_sizes[:16]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde maintenant les résultats sur le score de dice en fonction de la taille et du seuil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dices = np.array(list(dices.values()))\n",
    "dices3 = dices_array.reshape(16, 24)\n",
    "plt.imshow(dices3, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.xticks(np.arange(0, len(thresholds), 5), np.round(thresholds[::5], 2), rotation=45)\n",
    "plt.ylabel(\"Taille disque\")\n",
    "plt.title(\"Heatmap score Dice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom on 0.01 to 0.1 for threshold\n",
    "dices_array_zoom = dices_array[:, :10]\n",
    "plt.imshow(dices_array_zoom, cmap=\"hot\", interpolation=\"nearest\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.xticks(np.arange(0, 10), np.round(thresholds[:10], 2), rotation=45)\n",
    "plt.ylabel(\"Taille disque\")\n",
    "plt.title(\"Heatmap score Dice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best disk size and threshold couple\n",
    "best_disk_index, best_threshold_index = np.unravel_index(\n",
    "    np.argmax(dices_array, axis=None), dices_array.shape\n",
    ")\n",
    "best_disk = disk_sizes[best_disk_index]\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "print(\n",
    "    f\"Meilleur couple (disk, threshold): ({best_disk}, {best_threshold}) avec un score de {dices_array[best_disk_index, best_threshold_index]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le heatmap indique que l'argument critique est le seuillage. Nous avons arrêté le calcul du disque taille 16 car l'algorithme prenait trop de temps sans trop de différence de résultat.  Nous avons trouvé comme meilleur paramètre $\\{\\text{seuillage}, \\text{taille disque}\\}$  sur le jeu de données d'entrainements la valeur : $(6,0.04)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On teste maintenant sur les images de test\n",
    "dices = []\n",
    "step = 3\n",
    "for i in range(test_start, test_end):\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual1 = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    imgg = rgb2gray(img)\n",
    "    binmask = imgg > 0.1\n",
    "    imgclo = closing(imgg, disk(best_disk))\n",
    "    bth = imgclo - imgg\n",
    "    vessels = (bth > best_threshold) * binmask\n",
    "    score_dice = dice(manual1, vessels)\n",
    "    dices.append(score_dice)\n",
    "    print(\"------ Image \", i, f\" (dice {score_dice}) ------\")\n",
    "    if i % step == 0:\n",
    "        viewlist(\n",
    "            (imgg, imgclo, manual1, bth * binmask, vessels),\n",
    "            titles=[\n",
    "                \"GT Image\",\n",
    "                \"Ouverture\",\n",
    "                \"GT Manuel\",\n",
    "                \"Black top hat\",\n",
    "                f\"Seuillage Otsu {score_dice}\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "print(\n",
    "    f\" Dice moyen sur les {len(dices)} images:  {np.mean(dices)}. Le meilleur dice est de {np.max(dices)} sur l'image {np.argmax(dices) + test_start}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices)}, max: {np.max(dices)}, std: {np.std(dices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__conclusion__: Le résultat moyen est maintenant 0.68 ( légèrement meilleur que 0.67 notre dernier résultat ) Mais il y a encore trop de bruit. On va essayer les autres méthodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1- Trying some denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import area_opening, area_closing\n",
    "\n",
    "\n",
    "def mmdenoise(img, iter, clofirst=True):\n",
    "    imgi = img.copy()\n",
    "    for i in range(1, iter):\n",
    "        if clofirst:\n",
    "            imgc = area_closing(imgi, i)\n",
    "            imgo = area_opening(imgc, i)\n",
    "            imgi = imgo\n",
    "        else:\n",
    "            imgo = area_opening(imgi, i)\n",
    "            imgc = area_closing(imgo, i)\n",
    "            imgi = imgc\n",
    "        print(\".\", end=\"\")\n",
    "    return imgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On reload au cas où\n",
    "img1 = iio.imread(f\"Eye_fundus/images/{training_start}_training.tif\")\n",
    "gtmask1 = iio.imread(f\"Eye_fundus/mask/{training_start}_training_mask.gif\")\n",
    "manual1 = iio.imread(f\"Eye_fundus/1st_manual/{training_start}_manual1.gif\")\n",
    "imgg1 = rgb2gray(img1)\n",
    "binmask1 = imgg1 > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgg1d = mmdenoise(imgg1, 8, clofirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewlist((imgg1, imgg1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleseg(fundus, mask, diameter, threshold):\n",
    "    imgclo1 = closing(fundus, disk(diameter))\n",
    "    bth1 = (imgclo1 - fundus) >= threshold\n",
    "    return bth1 * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = simpleseg(imgg1, binmask1, 13, 0.05)\n",
    "ssd1 = simpleseg(imgg1d, binmask1, 13, 0.035)  ## with denoising, we can threshold lower\n",
    "viewlist(\n",
    "    (manual1, ss1, ssd1),\n",
    "    titles=[\"GT\", \"Simple Segmentation\", \"Simple Segmentation Denoised\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simple segmentation not denoise score =\", dice(manual1, ss1))\n",
    "print(\"Simple segmentation, denoised.  score =\", dice(manual1, ssd1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising seems to help. You can try various denoising methods available in scikit image, look in particular to Non-local means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.restoration import denoise_nl_means\n",
    "\n",
    "imgg1nld = denoise_nl_means(\n",
    "    imgg1, patch_size=9, h=0.01, patch_distance=22, preserve_range=True\n",
    ")  ## it is worth it to explore the parameters of this method\n",
    "\n",
    "ssnld1 = simpleseg(imgg1nld, binmask1, 13, 0.02)\n",
    "\n",
    "viewlist((imgg1, imgg1nld, ssnld1))\n",
    "\n",
    "print(\"Score of the non-local-means denoising method= \", dice(manual1, ssnld1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant essayer d'optimiser la moyenne non locale avec le patch size et la distance de patch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut aussi évaluer la méthode mmdenoise sur les images 21 à 31\n",
    "dices = []\n",
    "step = 3\n",
    "for i in range(test_start, test_end):\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual1 = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    imgg = rgb2gray(img)\n",
    "    binmask = imgg > 0.1\n",
    "    imgg_denoised = mmdenoise(imgg, 8, clofirst=False)\n",
    "    ss = simpleseg(imgg_denoised, binmask, 13, 0.035)\n",
    "    score_dice = dice(manual1, ss)\n",
    "    dices.append(score_dice)\n",
    "\n",
    "print(\n",
    "    f\" Dice moyen sur les {len(dices)} images:  {np.mean(dices)}. Le meilleur dice est de {np.max(dices)} sur l'image {np.argmax(dices) + test_start}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices)}, max: {np.max(dices)}, std: {np.std(dices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On optimise les paramètres de la méthode de denoising et on trace une heatmap du dice score sur cette image\n",
    "dices = {}\n",
    "patch_sizes = np.arange(5, 15, 1)\n",
    "hs = np.arange(0.001, 0.1, 0.01)\n",
    "for patch_size in tqdm(patch_sizes):\n",
    "    for h in hs:\n",
    "        imgg1nld = denoise_nl_means(\n",
    "            imgg1, patch_size=patch_size, h=h, patch_distance=22, preserve_range=True\n",
    "        )\n",
    "        ssnld1 = simpleseg(imgg1nld, binmask1, 13, 0.02)\n",
    "        score_dice = dice(manual1, ssnld1)\n",
    "        dices[(patch_size, h)] = score_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_patch_size, best_h = max(dices, key=dices.get)\n",
    "print(\n",
    "    f\"Meilleur couple (patch_size, h): ({best_patch_size}, {best_h}) avec un score de {dices[(best_patch_size, best_h)]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut maintenant évaluer cette méthode sur les images 31 à 40\n",
    "dices = []\n",
    "for i in range(test_start, test_end):\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual1 = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    imgg = rgb2gray(img)\n",
    "    binmask = imgg > 0.1\n",
    "    imgg_nld = denoise_nl_means(\n",
    "        imgg,\n",
    "        patch_size=best_patch_size,\n",
    "        h=best_h,\n",
    "        patch_distance=22,\n",
    "        preserve_range=True,\n",
    "    )\n",
    "    ss = simpleseg(imgg_nld, binmask, 13, 0.02)\n",
    "    score_dice = dice(manual1, ss)\n",
    "    dices.append(score_dice)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\" Dice moyen sur les {len(dices)} images:  {np.mean(dices)}. Le meilleur dice est de {np.max(dices)} sur l'image {np.argmax(dices) + test_start}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices)}, max: {np.max(dices)}, std: {np.std(dices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# déterminons la patch distance\n",
    "dices_patch = {}\n",
    "manual1 = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "patch_distances = np.arange(15, 30, 1)\n",
    "for patch_distance in tqdm(patch_distances):\n",
    "    imgg1nld = denoise_nl_means(\n",
    "        imgg1,\n",
    "        patch_size=best_patch_size,\n",
    "        h=best_h,\n",
    "        patch_distance=patch_distance,\n",
    "        preserve_range=True,\n",
    "    )\n",
    "    ssnld1 = simpleseg(imgg1nld, binmask1, 13, 0.02)\n",
    "    score_dice = dice(manual1, ssnld1)\n",
    "    dices_patch[patch_distance] = score_dice\n",
    "\n",
    "best_patch_distance = max(dices_patch, key=dices_patch.get)\n",
    "print(\n",
    "    f\"Meilleur patch_distance: {best_patch_distance} avec un score de {dices_patch[best_patch_distance]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on images 21 to 31 avec tous les meilleurs paramètres\n",
    "dices_nld = []\n",
    "for i in range(test_start, test_end):\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    imgg = rgb2gray(img)\n",
    "    binmask = imgg > 0.1\n",
    "    imgg_nld = denoise_nl_means(\n",
    "        imgg,\n",
    "        patch_size=best_patch_size,\n",
    "        h=best_h,\n",
    "        patch_distance=best_patch_distance,\n",
    "        preserve_range=True,\n",
    "    )\n",
    "    ss = simpleseg(imgg_nld, binmask, 13, 0.02)\n",
    "    score_dice = dice(manual, ss)\n",
    "    dices_nld.append(score_dice)\n",
    "\n",
    "print(\n",
    "    f\" Dice moyen sur les {len(dices_nld)} images:  {np.mean(dices_nld)}. Le meilleur dice est de {np.max(dices_nld)} sur l'image {np.argmax(dices_nld) + 31}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices_nld)}, max: {np.max(dices_nld)}, std: {np.std(dices_nld)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Nous avons donc optimisé les paramètres de la méthode moyenne non locale ce qui donne un meilleur coupe (patch_size,h) de (5,0.001) basé sur l'image 31 .\n",
    " Testé sur la base de test, on obtient un Dice de 0.37.  On optimise alors la patch distance pour trové une distance de 0.37 qui es très semblable au résultat initial. ¨Pour les images en test avec l'algorithme de denoising, ce choix manuel semblent fortement détérioré la qualité de ségmentation \n",
    " Avec mmdenoise on a un score de 0.67 ce qui est semblable au dénoising manuel.\n",
    " Mais on  n'a fait que faire du preprocessing à l'algorithme de segmentation, on pourrait voir le résultat si on modifie le résultat de l'algorithme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2- Using a learned gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install higra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import higra as hg\n",
    "import cv2\n",
    "\n",
    "\n",
    "import urllib.request as request\n",
    "\n",
    "exec(\n",
    "    request.urlopen(\n",
    "        \"https://github.com/higra/Higra-Notebooks/raw/master/utils.py\"\n",
    "    ).read(),\n",
    "    globals(),\n",
    ")\n",
    "\n",
    "\n",
    "detector = cv2.ximgproc.createStructuredEdgeDetection(get_sed_model_file())\n",
    "\n",
    "img1f = img1.astype(np.float32) / 255  ## for this we use the colour image as input\n",
    "\n",
    "gradient_image = detector.detectEdges(img1f)\n",
    "\n",
    "imview(gradient_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we need to use a shrunk mask\n",
    "\n",
    "from skimage.morphology import erosion, opening\n",
    "\n",
    "smask1 = erosion(binmask1, disk(15))\n",
    "\n",
    "gradvessel1 = gradient_image * smask1\n",
    "imview(gradvessel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use a white top-hat on the gradient\n",
    "\n",
    "gradvesseld1 = gradvessel1 - opening(gradvessel1, disk(2)) > 0.01\n",
    "imview(gradvesseld1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score of the learned gradient method= \", dice(manual1, gradvesseld1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On optimise maintenant le disque d'érosion et d'ouverture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a grid of plt.subplots with size of disk of erosion and opening pamaraters\n",
    "# for every combination of erosion and opening, take the best threshold and then compute the dice score\n",
    "# show threshold and dice on title of subfigure\n",
    "\n",
    "dices = {}\n",
    "images_save = {}  # used for subplot grid\n",
    "disk_sizes_erosion = np.arange(1, 11, 1)\n",
    "disk_sizes_opening = np.arange(1, 11, 1)\n",
    "thresholds = np.arange(0.01, 0.1, 0.01)\n",
    "gradient_image = detector.detectEdges(img1f)\n",
    "\n",
    "for disk_size_e in disk_sizes_erosion:\n",
    "    for disk_size_o in tqdm(disk_sizes_opening, leave=False):\n",
    "        smask1 = erosion(binmask1, disk(disk_size_e))\n",
    "        gradvessel = gradient_image * smask1\n",
    "        current_best_dice = 0\n",
    "        best_threshold = 0\n",
    "        for threshold in thresholds:\n",
    "            gradvesseld = (\n",
    "                gradvessel - opening(gradvessel, disk(disk_size_o)) > threshold\n",
    "            )\n",
    "            score_dice = dice(manual1, gradvesseld)\n",
    "            if score_dice > current_best_dice:\n",
    "                current_best_dice = score_dice\n",
    "                best_threshold = threshold\n",
    "\n",
    "        dices[(disk_size_e, disk_size_o)] = current_best_dice\n",
    "        # recompute gradvesseld with best threshold for image\n",
    "        gradvessel = gradient_image * smask1\n",
    "        gradvesseld = (\n",
    "            gradvessel - opening(gradvessel, disk(disk_size_o)) > best_threshold\n",
    "        )\n",
    "        images_save[(disk_size_e, disk_size_o)] = gradvesseld\n",
    "\n",
    "best_disk_size_e, best_disk_size_o = max(dices, key=dices.get)\n",
    "print(\n",
    "    f\"Meilleur couple (disk_size_e, disk_size_o): ({best_disk_size_e}, {best_disk_size_o}) avec un score de {dices[(best_disk_size_e, best_disk_size_o)]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the subplot grid\n",
    "fig, axs = plt.subplots(\n",
    "    len(disk_sizes_erosion), len(disk_sizes_opening), figsize=(20, 20)\n",
    ")\n",
    "for i, disk_size_e in enumerate(disk_sizes_erosion):\n",
    "    for j, disk_size_o in enumerate(disk_sizes_opening):\n",
    "        axs[i, j].imshow(images_save[(disk_size_e, disk_size_o)])\n",
    "        axs[i, j].set_title(\n",
    "            f\"e: {disk_size_e}, o: {disk_size_o}, Dice: {round(dices[(disk_size_e, disk_size_o)], 2)}\"\n",
    "        )\n",
    "        axs[i, j].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = []\n",
    "for i in range(test_start, test_end):\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    imgf = img.astype(np.float32) / 255\n",
    "    gradient_image = detector.detectEdges(imgf)\n",
    "    smask = erosion(binmask, disk(best_disk_size_e))\n",
    "    gradvessel = gradient_image * smask\n",
    "\n",
    "    current_best_dice = 0\n",
    "    best_threshold = 0\n",
    "    for threshold in thresholds:\n",
    "        gradvesseld = (\n",
    "            gradvessel - opening(gradvessel, disk(best_disk_size_o)) > threshold\n",
    "        )\n",
    "        score_dice = dice(manual, gradvesseld)\n",
    "        if score_dice > current_best_dice:\n",
    "            current_best_dice = score_dice\n",
    "            best_threshold = threshold\n",
    "\n",
    "    gradvessel = gradient_image * smask\n",
    "    gradvesseld = (\n",
    "        gradvessel - opening(gradvessel, disk(best_disk_size_o)) > best_threshold\n",
    "    )\n",
    "    dices.append(dice(manual, gradvesseld))\n",
    "\n",
    "print(\n",
    "    f\" Dice moyen sur les {len(dices)} images:  {np.mean(dices)}. Le meilleur dice est de {np.max(dices)} sur l'image {np.argmax(dices) + test_start}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices)}, max: {np.max(dices)}, std: {np.std(dices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__conclusion__: On a le plus petit écart type pour le moment mais un Dice décevant: cette technique n'apporte rien de plus. Un des problèmes est ici que nous obtenons comme positif le contour de l'oeil (et donc FP ce qui fait baisser le Dice). Visuellement, il y a beaucoup de veines qui ne sont pas segmentées donc même en supprimant cet effet on n'aura pas un bon score. Concernant l'effet des deux paramètres, nous obtenons les effets attendus concernant la taille du disque de l'érosion et de la dilatation.\n",
    "Nous allons donc passer à une approche par connectivité pour tenter d'améliorer le Dice. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3- using a connective approach\n",
    "\n",
    "Here we use the interactive approach from the higra tutorial. Try to find a good tree and a good rule, then apply it on the whole database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start from the black top-hat image\n",
    "\n",
    "imgclo1 = closing(imgg1, disk(15))\n",
    "bth1 = (imgclo1 - imgg1) * smask1  ## to avoid border effects\n",
    "\n",
    "size = bth1.shape\n",
    "print(\"Image size:\", size)\n",
    "graph = hg.get_4_adjacency_graph(size)\n",
    "tree, altitudes = hg.component_tree_max_tree(graph, bth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import interact, FloatSlider\n",
    "\n",
    "\n",
    "def subtractive_rule(tree, altitudes, deleted_nodes):\n",
    "    # altitudes difference with parent node\n",
    "    delta_altitudes = altitudes - altitudes[tree.parents()]\n",
    "    # remove deleted nodes\n",
    "    delta_altitudes[deleted_nodes] = 0\n",
    "    # restore root absolute alitudes\n",
    "    delta_altitudes[tree.root()] = altitudes[tree.root()]\n",
    "    # accumulated deltas without deleted nodes\n",
    "    altitudes = hg.propagate_sequential_and_accumulate(\n",
    "        tree, delta_altitudes, hg.Accumulators.sum\n",
    "    )\n",
    "\n",
    "    return altitudes, deleted_nodes\n",
    "\n",
    "\n",
    "trees = {\n",
    "    \"Min Tree\": hg.component_tree_min_tree(graph, bth1),\n",
    "    \"Max Tree\": hg.component_tree_max_tree(graph, bth1),\n",
    "    \"Tree of Shapes\": hg.component_tree_tree_of_shapes_image2d(bth1),\n",
    "}\n",
    "\n",
    "attributes = {\n",
    "    \"area\": lambda tree, altitudes: hg.attribute_area(tree),\n",
    "    \"height\": lambda tree, altitudes: hg.attribute_height(tree, altitudes) * 4,\n",
    "    \"compactness\": lambda tree, altitudes: hg.attribute_compactness(tree) * 1000,\n",
    "}\n",
    "\n",
    "## Compute relevant features\n",
    "filtering_rule = {\n",
    "    \"direct\": lambda tree, altitudes, deleted_nodes: (altitudes, deleted_nodes),\n",
    "    \"min\": lambda tree, altitudes, deleted_nodes: (\n",
    "        altitudes,\n",
    "        hg.propagate_sequential(tree, deleted_nodes, np.logical_not(deleted_nodes)),\n",
    "    ),\n",
    "    \"max\": lambda tree, altitudes, deleted_nodes: (\n",
    "        altitudes,\n",
    "        hg.accumulate_and_min_sequential(\n",
    "            tree, deleted_nodes, np.ones((tree.num_leaves(),)), hg.Accumulators.min\n",
    "        ),\n",
    "    ),\n",
    "    \"subtractive\": subtractive_rule,\n",
    "}\n",
    "\n",
    "\n",
    "## Taken from tutorial\n",
    "def filtering(sTree, sAttr, sRule, sThreshold):\n",
    "    tree, altitudes = trees[sTree]\n",
    "    attribute = attributes[sAttr](tree, altitudes)\n",
    "\n",
    "    deleted_nodes = attribute < sThreshold\n",
    "\n",
    "    altitudes, deleted_nodes = filtering_rule[sRule](tree, altitudes, deleted_nodes)\n",
    "\n",
    "    result = hg.reconstruct_leaf_data(tree, altitudes, deleted_nodes)\n",
    "\n",
    "    imshow(result, cmap=\"gray\")\n",
    "\n",
    "\n",
    "# interact(filtering,\n",
    "#         sTree=['Min Tree', 'Max Tree', 'Tree of Shapes'],\n",
    "#         sAttr=['area', 'height', 'compactness'],\n",
    "#         sRule=['direct', 'min', 'max', 'subtractive'],\n",
    "#         sThreshold=FloatSlider(min=0, max=1000, step=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a combination of subtractive rule, attributes and trees to find the best dice score\n",
    "# make a grid search of the best parameters\n",
    "# show the heatmap of the dice score for every sRule in filtering_rule. Every time find best threshold\n",
    "\n",
    "\n",
    "for sRule in filtering_rule.keys():\n",
    "    dices = {}\n",
    "    for sTree in trees.keys():\n",
    "        for sAttr in attributes.keys():\n",
    "            best_threshold = 0\n",
    "            current_best_dice = 0\n",
    "            for sThreshold in tqdm(np.arange(0, 1000, 10), leave=False):\n",
    "                tree, altitudes = trees[sTree]\n",
    "                attribute = attributes[sAttr](tree, altitudes)\n",
    "                deleted_nodes = attribute < sThreshold\n",
    "                altitudes, deleted_nodes = filtering_rule[sRule](\n",
    "                    tree, altitudes, deleted_nodes\n",
    "                )\n",
    "                result = hg.reconstruct_leaf_data(tree, altitudes, deleted_nodes)\n",
    "                bin_result = result > 0.05\n",
    "                score_dice = dice(manual1, bin_result)\n",
    "                if score_dice > current_best_dice:\n",
    "                    current_best_dice = score_dice\n",
    "                    best_threshold = sThreshold\n",
    "            dices[(sTree, sAttr)] = current_best_dice\n",
    "\n",
    "    dices_array = np.array(list(dices.values()))\n",
    "    dices_array = dices_array.reshape(len(trees), len(attributes))\n",
    "    plt.imshow(dices_array, cmap=\"hot\", interpolation=\"nearest\")\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Attributes\")\n",
    "    plt.xticks(np.arange(0, len(attributes), 1), list(attributes.keys()), rotation=45)\n",
    "    plt.ylabel(\"Trees\")\n",
    "    plt.yticks(np.arange(0, len(trees), 1), list(trees.keys()), rotation=45)\n",
    "    plt.title(f\"Dice pour {sRule}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgclo1 = closing(imgg1, disk(15))\n",
    "bth1 = (imgclo1 - imgg1) * smask1  ## to avoid border effects\n",
    "\n",
    "size = bth1.shape\n",
    "print(\"Image size:\", size)\n",
    "graph = hg.get_4_adjacency_graph(size)\n",
    "tree, altitudes = hg.component_tree_max_tree(graph, bth1)\n",
    "size = bth1.shape\n",
    "print(\"Image size:\", size)\n",
    "graph = hg.get_4_adjacency_graph(size)\n",
    "tree, altitudes = hg.component_tree_max_tree(graph, bth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = []\n",
    "sTree = trees[\"Max Tree\"]\n",
    "sAttr = attributes[\"area\"]\n",
    "sRule = filtering_rule[\"subtractive\"]\n",
    "\n",
    "for i in range(test_start, test_end):\n",
    "    # ouverture classique\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "\n",
    "    #  preprocessing\n",
    "    binmask = imgg > 0.1\n",
    "    imgg = rgb2gray(img)\n",
    "    imgclo = closing(imgg, disk(15))\n",
    "    smask = erosion(binmask, disk(best_disk_size_e))\n",
    "    bth = (imgclo - imgg) * smask\n",
    "\n",
    "    # hg\n",
    "    size = bth1.shape\n",
    "    graph = hg.get_4_adjacency_graph(size)\n",
    "    tree, altitudes = hg.component_tree_max_tree(graph, bth)\n",
    "    sAttr = hg.attribute_area(tree)\n",
    "    sTree = tree\n",
    "    sRule = subtractive_rule\n",
    "\n",
    "    # boucle pour trouver le meilleur threshold\n",
    "    best_threshold = 0\n",
    "    current_best_dice = 0\n",
    "    for sThreshold in np.arange(0, 1000, 10):\n",
    "        attribute = sAttr\n",
    "        deleted_nodes = attribute < sThreshold\n",
    "        altitudes, deleted_nodes = sRule(tree, altitudes, deleted_nodes)\n",
    "        result = hg.reconstruct_leaf_data(tree, altitudes, deleted_nodes)\n",
    "        bin_result = result > 0.04\n",
    "        score_dice = dice(manual, bin_result)\n",
    "        if score_dice > current_best_dice:\n",
    "            current_best_dice = score_dice\n",
    "            best_threshold = sThreshold\n",
    "    dices.append(current_best_dice)\n",
    "\n",
    "print(\n",
    "    f\" Dice moyen sur les {len(dices)} images:  {np.mean(dices)}. Le meilleur dice est de {np.max(dices)} sur l'image {np.argmax(dices) + test_start}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices)}, max: {np.max(dices)}, std: {np.std(dices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a fait ici toutes les combinaisons possibles entre les arbres et attributs, et on a repris le seuil à $0.04$ pour tester binariser les vaisseaux comme c'était le seuil qui marchait le mieux auparavant. Le meilleur Dice est obtenu pour la combinaison max tree et area. \n",
    "On remarque que le Dice obtenu est semblable avec avec le seuillage manuel. Cela ne marche pas dans notre cas. Nous allons maintenant essayer avec les filtres plus classiques et adaptés à notre problème: filtres de Frangi et Sato. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Frangi et Sato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "\n",
    "from skimage.filters import frangi\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import rank\n",
    "from skimage.morphology import square\n",
    "from skimage.segmentation import watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image 31, apply frangi filter and show the result\n",
    "\n",
    "img21 = iio.imread(f\"Eye_fundus/images/{training_start}_training.tif\")\n",
    "gtmask21 = iio.imread(f\"Eye_fundus/mask/{training_start}_training_mask.gif\")\n",
    "manua21 = iio.imread(f\"Eye_fundus/1st_manual/{training_start}_manual1.gif\")\n",
    "img21 = rgb2gray(img21)\n",
    "binmask21 = img21 > 0.1\n",
    "img21_frangi = frangi(img21 * binmask21)\n",
    "viewlist((img21, img21_frangi), titles=[\"Original\", \"Frangi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le filtre de Frangi donne des résultats étranges, on va preprocess l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "img21_clahe = clahe.apply((img21 * 255).astype(np.uint8))\n",
    "frangi_clahe = frangi(img21_clahe)\n",
    "frangi_clahe_mask = frangi_clahe * binmask21\n",
    "dice_frangi = dice(gtmask21, frangi_clahe)\n",
    "dice_frangi_mask = dice(gtmask21, frangi_clahe_mask)\n",
    "viewlist(\n",
    "    (img21, img21_clahe, frangi_clahe, frangi_clahe_mask),\n",
    "    titles=[\n",
    "        \"Originale\",\n",
    "        \"CLAHE\",\n",
    "        f\"Frangi (dice: {dice_frangi})\",\n",
    "        f\"Frangi mask (dice: {dice_frangi_mask})\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = []\n",
    "for i in range(test_start, test_end):\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    img = rgb2gray(img)\n",
    "    binmask = img > 0.1\n",
    "    img_clahe = clahe.apply((img * 255).astype(np.uint8))\n",
    "    frangi_clahe = frangi(img_clahe)\n",
    "    frangi_clahe_mask = frangi_clahe * binmask\n",
    "    score_dice = dice(gtmask, frangi_clahe_mask)\n",
    "    dices.append(score_dice)\n",
    "\n",
    "print(\n",
    "    f\" Dice moyen sur les {len(dices)} images:  {np.mean(dices)}. Le meilleur dice est de {np.max(dices)} sur l'image {np.argmax(dices) + test_start}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices)}, max: {np.max(dices)}, std: {np.std(dices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Sato filtre on image 21\n",
    "from skimage.filters import sato\n",
    "\n",
    "\n",
    "img21 = iio.imread(f\"Eye_fundus/images/{training_start}_training.tif\")\n",
    "gtmask21 = iio.imread(f\"Eye_fundus/mask/{training_start}_training_mask.gif\")\n",
    "manual21 = iio.imread(f\"Eye_fundus/1st_manual/{training_start}_manual1.gif\")\n",
    "img21_gray = rgb2gray(img21)  # Convert image to grayscale\n",
    "binmask21 = img21_gray > 0.1\n",
    "img21_clahe = clahe.apply((img21_gray * 255).astype(np.uint8))\n",
    "sato_clahe = sato(img21_clahe)\n",
    "sato_clahe_mask = sato_clahe * binmask21\n",
    "dice_sato = dice(gtmask21, sato_clahe)\n",
    "dice_sato_mask = dice(gtmask21, sato_clahe_mask)\n",
    "viewlist(\n",
    "    (img21, manual21, img21_clahe, sato_clahe, sato_clahe_mask),\n",
    "    titles=[\n",
    "        \"Originale\",\n",
    "        \"GT\",\n",
    "        \"CLAHE\",\n",
    "        f\"Sato (dice: {dice_sato})\",\n",
    "        f\"Sato mask (dice: {dice_sato_mask})\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dices = []\n",
    "step = 3\n",
    "for i in range(test_start, test_end):\n",
    "    img = iio.imread(f\"Eye_fundus/images/{i}_training.tif\")\n",
    "    gtmask = iio.imread(f\"Eye_fundus/mask/{i}_training_mask.gif\")\n",
    "    manual = iio.imread(f\"Eye_fundus/1st_manual/{i}_manual1.gif\")\n",
    "    img = rgb2gray(img)\n",
    "    binmask = img > 0.1\n",
    "    img_clahe = clahe.apply((img * 255).astype(np.uint8))\n",
    "    sato_clahe = sato(img_clahe)\n",
    "    sato_clahe_mask = sato_clahe * binmask\n",
    "    score_dice = dice(gtmask, sato_clahe_mask)\n",
    "    dices.append(score_dice)\n",
    "    # print and view list of images\n",
    "    print(f\"------ Image {i} (dice: {score_dice}) ------\")\n",
    "    if i % step == 0:\n",
    "        viewlist(\n",
    "            (img, manual, img_clahe, sato_clahe, sato_clahe_mask),\n",
    "            titles=[\"Originale\", \"GT\", \"CLAHE\", f\"Sato\", f\"Sato mask\"],\n",
    "        )\n",
    "\n",
    "print(\n",
    "    f\" Dice moyen sur les {len(dices)} images:  {np.mean(dices)}. Le meilleur dice est de {np.max(dices)} sur l'image {np.argmax(dices) + test_start}\"\n",
    ")\n",
    "print(f\"min: {np.min(dices)}, max: {np.max(dices)}, std: {np.std(dices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons bien ici que la méthode de Frangi est très adaptée à noter problème car il y a une grande amélioration dans le Dice ( on est maintenant à $0.88$). Elle est quand même nettement en dessous de la méthode de Sato qui donne un Dice de $0.98$ sur la première image. EN testant sur les images de test on a un résultat $0.97$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Approche par apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de données est plutôt petite, donc un apprentissage classique par U-Net par exemple peut ne pas fonctionner très bien. D'autre part les annotations de la partie fine des vaisseaux sanguins (vers les extrémités) est quasiment négligeable par rapport au reste. \n",
    "\n",
    "Pour améliorer les résultats, on peut utiliser une approche par apprentissage avec une partie morphologique, en suivant l'article \n",
    "\n",
    "https://arxiv.org/pdf/2404.03010\n",
    "\n",
    "Il est possible **(optionnellement !)** d'augmenter et vérifier son travail sur une BDD différente de celle de DRIVE, voir par exemple\n",
    "\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC10219065/pdf/jcm-12-03587.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critique du Dice\n",
    "\n",
    "La métrique Dice est largement utilisée en imagerie médicale, mais elle présente certaines limitations. En particulier, il est crucial de supprimer correctement le contour de l'œil, sous peine d'obtenir un score Dice biaisé en raison de la grande taille de cette région. Certaines méthodes tendent à supprimer davantage les vaisseaux ainsi que cette zone, ce qui réduit artificiellement le nombre de faux positifs et peut induire en erreur lors du choix d'une méthode, comme observé dans la dernière cellule.\n",
    "\n",
    "De plus, cette métrique repose sur une vérité terrain, qui varie naturellement en fonction du médecin qui effectue l'annotation. Une approche plus avancée et réaliste consisterait à intégrer l'expertise de plusieurs médecins pour générer une carte de densité de vérité terrain. Cette dernière pourrait alors servir de référence, à l’instar des jeux de données de segmentation, afin d’obtenir une évaluation plus robuste des résultats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__conclusion__:\n",
    "\n",
    "La conclusion et notre cheinement se trouve en début de notebook. Voici les techniques que nous avons mises en place: \n",
    "\n",
    "Vous pouvez tenter tout ou partie des approches suivantes:\n",
    "\n",
    "- ✔️Try to optimize the parameters of the approach, maybe on half the database, test on the other half\n",
    "    - The diameter of the disk\n",
    "    - The threshold\n",
    "    - Try to improve the mask, it may help\n",
    "\n",
    "- ✔️Try some connective approach, under the assuption that the vessel network is connected, using **higra**\n",
    "- ✔️Try using a well-researched gradient instead or before the top hat, eg the Dollar gradient (see `cv2.ximgproc.createStructuredEdgeDetection` from `higra_tutoria_01`)\n",
    "- ✔️Try using some denoising and image simplification\n",
    "- ✔️Try using the *Vesselness* filters from scikit-image, [especially designed to enhance vessels](https://scikit-image.org/docs/stable/api/skimage.filters.html). \n",
    "    - Try the Frangi filter and \n",
    "    - Try the Sato tubeness enhancement.\n",
    "    They both require some parameter tuning\n",
    "- ✔️Take a critical approach to the metric. Is Dice the best metric? Are the annotation of good enough quality ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
