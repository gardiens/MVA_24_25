{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ne pas executer à l'intérieur de Visual Studio Code\n",
    "# %matplotlib notebook\n",
    "## A l'intérieur de Google Colab, utiliser plutôt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematical morphology Segmentation Tutorial\n",
    "\n",
    "Hugues Talbot, 2023 April 11\n",
    "\n",
    "## Introduction to numpy, scipy, matplotlib, scikit-image\n",
    "\n",
    "The main \"modern\" packages to perform image processing in python are\n",
    "\n",
    "- numpy\n",
    "- scipy\n",
    "- matplotlib\n",
    "- scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### To help viewing images\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## to view a single image\n",
    "def imview(image, cmap=\"gray\", interpolation=\"nearest\", figsize=(6, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image, cmap=cmap, interpolation=interpolation)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## to view 3 images at once\n",
    "def viewlist(images, cmap=\"gray\", figsize=(18, 6)):\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    columns = len(images)\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1, columns, i + 1)\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constructing a random color map for segmentation display\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "r = np.random.rand(256, 3)\n",
    "r[0] = [0, 0, 0]\n",
    "\n",
    "randcmap = colors.ListedColormap(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basics of numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = np.zeros((9, 9))\n",
    "check[::2, 1::2] = 1\n",
    "check[1::2, ::2] = 1\n",
    "imview(check, cmap=\"gray\", interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-image\n",
    "\n",
    "scikit image contains many state-of-the-art image processing methods\n",
    "\n",
    "https://scikit-image.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = data.camera()\n",
    "print(\"Image type\", camera.dtype)\n",
    "print(\"Image shape\", camera.shape)\n",
    "\n",
    "from skimage import restoration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical morphology with scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "## a structuring element.\n",
    "morphology.disk(5)\n",
    "\n",
    "## example on a tiny image\n",
    "a = np.zeros((7, 7), dtype=np.int32)\n",
    "a[1:6, 2:5] = 1\n",
    "\n",
    "imview(a)\n",
    "\n",
    "ae = morphology.erosion(a, morphology.diamond(1)).astype(\n",
    "    np.uint8\n",
    ")  ## pour garder l'image codée en 8-bit\n",
    "\n",
    "imview(ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operators\n",
    "\n",
    "Try the same with dilation, openings and closings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greyscale morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import disk\n",
    "from skimage import filters\n",
    "\n",
    "coins = data.coins()\n",
    "coins_zoom = coins[10:80, 300:370]\n",
    "median_coins = filters.rank.median(coins_zoom, disk(1))  ## classical median filter\n",
    "from skimage import restoration\n",
    "\n",
    "tv_coins = restoration.denoise_tv_chambolle(coins_zoom, weight=0.05)\n",
    "gaussian_coins = filters.gaussian(coins_zoom, sigma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewlist((coins_zoom, median_coins, tv_coins, gaussian_coins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## opérateurs de MM en niveaux de gris\n",
    "\n",
    "testez erosion / dilatation / ouverture / fermeture sur image de la pièce de monnaie \n",
    "et comparez (visuellement avec le filtre gaussien et médian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## votre code ici\n",
    "\n",
    "coins_open = morphology.opening(coins_zoom, morphology.diamond(1))\n",
    "coins_cloopen = morphology.closing(coins_open, morphology.diamond(1))\n",
    "\n",
    "viewlist((coins_zoom, coins_cloopen))\n",
    "\n",
    "## pareil, ouverture/fermeture par SE trop \"violent\"\n",
    "\n",
    "coins_areaopen = morphology.area_opening(coins_zoom, 4)\n",
    "coins_areaclopen = morphology.area_closing(coins_areaopen, 4)\n",
    "\n",
    "viewlist((tv_coins, coins_areaclopen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simplest segmentation method: thresholding\n",
    "\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "\n",
    "camera = data.camera()\n",
    "otsuval = filters.threshold_otsu(camera)\n",
    "\n",
    "## filtrage par filtre bilatéral\n",
    "filtered_camera = (restoration.denoise_bilateral(camera) * 255).astype(np.uint8)\n",
    "print(\"Image type: \", type(filtered_camera))\n",
    "\n",
    "bincam = (camera < otsuval).astype(np.uint8)\n",
    "bintvcam = (filtered_camera < otsuval).astype(np.uint8)\n",
    "\n",
    "viewlist((camera, bincam, bintvcam))\n",
    "## On constate que le filtrage bilatéral fait disparaitre des objets fins et allongés, en plus du bruit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que le filtrage bilatéral fait disparaitre des objets fins et allongés, en plus du bruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exemple sur l'image de neurones\n",
    "\n",
    "neurons = skimage.io.imread(\"Neuron.png\")\n",
    "neurons = neurons[:, :, 0]\n",
    "print(neurons.shape)\n",
    "\n",
    "otsuneuronval = filters.threshold_otsu(neurons)\n",
    "print(\"Threshold at \", otsuneuronval)\n",
    "# binneurons = (neurons < otsuneuronval-30).astype(np.uint8)\n",
    "imview((neurons < 40).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_neurons = (restoration.denoise_tv_chambolle(neurons, weight=1) * 255).astype(\n",
    "    np.uint8\n",
    ")\n",
    "bintvneurons = (tv_neurons < 40).astype(np.uint8)\n",
    "imview(bintvneurons)\n",
    "\n",
    "## On voit que la TV a le même comportement, c'est un problème difficile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la TV a le même comportement, c'est un problème difficile.\n",
    "On étudiera ce problème un peu plus tard (mini-projet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données synthétiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "l = 256\n",
    "\n",
    "\n",
    "def make_blobs(l, n, sigmadiv=4.0):\n",
    "    im = np.zeros((l, l))\n",
    "    points = l * np.random.random((2, n**2))\n",
    "    im[(points[0]).astype(np.int32), (points[1]).astype(np.int32)] = 1\n",
    "    im = filters.gaussian(im, sigma=l / (sigmadiv * n))\n",
    "    blobs = im > im.mean()\n",
    "    return blobs\n",
    "\n",
    "\n",
    "blobs = make_blobs(l, n, 4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imview(blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## smaller blobs\n",
    "from skimage.morphology import erosion, dilation, opening, closing\n",
    "\n",
    "smallblobs = dilation(erosion(blobs, morphology.disk(7)), morphology.disk(2))\n",
    "\n",
    "holyblobs = blobs * (1 - smallblobs)\n",
    "imview(holyblobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary connected components analysis\n",
    "\n",
    "- remove the components that touch the border\n",
    "- fill all the holes\n",
    "- segment the components (see below)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### border intersection\n",
    "\n",
    "- construct an image which is zero everywhere except the four borders\n",
    "- use this image and morphological reconstruction to find the objects that touch the border\n",
    "\n",
    "- hint: use skimage.morphology.reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_borders(n):\n",
    "    im = np.zeros((l, l)).astype(np.uint8)\n",
    "    im[0, :] = 1\n",
    "    im[:, 0] = 1\n",
    "    im[l - 1, :] = 1\n",
    "    im[:, l - 1] = 1\n",
    "    return im\n",
    "\n",
    "\n",
    "borders = empty_borders(n)\n",
    "imview(borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import reconstruction\n",
    "\n",
    "blob_borders = borders * holyblobs\n",
    "touch_borders = reconstruction(blob_borders, holyblobs)\n",
    "\n",
    "imview(touch_borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## border objects removed\n",
    "\n",
    "borderobj_removed = holyblobs - touch_borders\n",
    "imview(borderobj_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hole filling\n",
    "\n",
    "- use the preceeding procedure to fill all the holes of the connected components. \n",
    "- hint: holes are connected component of the *background* that do not touch the border of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_holes = 1 - borderobj_removed\n",
    "\n",
    "holes_borders = borders * white_holes\n",
    "holes_borders = reconstruction(holes_borders, white_holes)\n",
    "## argument selem -> footprint in newer versions of skimage (0.19 and later)\n",
    "\n",
    "noholes = 1 - holes_borders\n",
    "imview(noholes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## erosion-based reconstruction\n",
    "blackborders = 1 - borders\n",
    "blobborders = borderobj_removed * blackborders\n",
    "holes_borders = reconstruction(blackborders, blobborders, method=\"erosion\")\n",
    "imview(holes_borders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label all components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "all_labels = measure.label(noholes)\n",
    "\n",
    "imview(all_labels, cmap=randcmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## label only foreground\n",
    "blobs_labels = measure.label(blobs, background=0)\n",
    "imview(blobs_labels, cmap=randcmap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation d'objets jointifs\n",
    "\n",
    "Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "# Generate an initial image with two overlapping circles\n",
    "x, y = np.indices((80, 80))\n",
    "x1, y1, x2, y2 = 28, 28, 44, 52\n",
    "r1, r2 = 16, 20\n",
    "mask_circle1 = (x - x1) ** 2 + (y - y1) ** 2 < r1**2\n",
    "mask_circle2 = (x - x2) ** 2 + (y - y2) ** 2 < r2**2\n",
    "image = np.logical_or(mask_circle1, mask_circle2)\n",
    "\n",
    "\n",
    "# Now we want to separate the two objects in image\n",
    "# Generate the markers as local maxima of the distance\n",
    "# to the background\n",
    "from scipy import ndimage\n",
    "\n",
    "# distance = ndimage.distance_transform_edt(image)\n",
    "# local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)), labels=image)\n",
    "# markers = morphology.label(local_maxi)\n",
    "# labels_ws = watershed(-distance, markers, mask=image)\n",
    "\n",
    "\n",
    "def separate_overlapping_disks(binary_image, min_distance=1):\n",
    "    distance = ndimage.distance_transform_edt(binary_image)\n",
    "    local_maxi_coords = peak_local_max(\n",
    "        distance, min_distance=min_distance, footprint=np.ones((3, 3))\n",
    "    )\n",
    "    mask = np.zeros(distance.shape, dtype=bool)\n",
    "    mask[tuple(local_maxi_coords.T)] = True\n",
    "    markers, _ = scipy.ndimage.label(mask)\n",
    "    # markers = morphology.label(local_maxi_coords)\n",
    "    labels_ws = watershed(-distance, markers, mask=binary_image)\n",
    "    return (labels_ws, markers)\n",
    "\n",
    "\n",
    "labels_ws, markers = separate_overlapping_disks(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imview(image)\n",
    "imview(markers)\n",
    "imview(labels_ws)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Random Walker instead of the Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation\n",
    "\n",
    "# Transform markers image so that 0-valued pixels are to\n",
    "# be labelled, and -1-valued pixels represent background\n",
    "markers[~image] = -1\n",
    "labels_rw = segmentation.random_walker(image, markers)\n",
    "\n",
    "imview(labels_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply to blogs image\n",
    "\n",
    "imview(noholes)\n",
    "\n",
    "separate_blobs, markers = separate_overlapping_disks(noholes)\n",
    "separate_blobs_filtered, markers = separate_overlapping_disks(noholes, min_distance=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imview(separate_blobs, cmap=randcmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imview(separate_blobs_filtered, cmap=randcmap)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversegmentation\n",
    "\n",
    "We see that the blobs are oversegmented, playing with the parameter min_distance allowed us to ameliorate the problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessing label images\n",
    "\n",
    "skimage provides several utility functions that can be used on label images (ie images where different discrete values identify different regions). Functions names are often self-explaining: \n",
    "- skimage.segmentation.clear_border(), \n",
    "- skimage.segmentation.relabel_from_one(), \n",
    "- skimage.morphology.remove_small_objects(), \n",
    "\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## measuring regions properties\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = measure.regionprops(labels_rw)\n",
    "print(\"Areas:\", [prop.area for prop in properties])\n",
    "print(\"Perimeters:\", [prop.perimeter for prop in properties])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "- Use the binary image of the coins and background from the previous exercise.\n",
    "- Compute an image of labels for the different coins.\n",
    "- Compute the size and eccentricity of all coins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = data.coins()\n",
    "mask = coins > filters.threshold_otsu(coins)\n",
    "clean_border = segmentation.clear_border(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imview(clean_border)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2\n",
    "\n",
    "- Download an image of _bacillus subtilis_ at \n",
    "\n",
    "https://github.com/justinbois/bootcamp/raw/master/data/bsub_100x_cfp.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import urllib.request\n",
    "import skimage\n",
    "import skimage.io\n",
    "# Download the file from `url` and save it locally under `file_name`:\n",
    "\n",
    "url = \"https://github.com/justinbois/bootcamp/raw/master/data/bsub_100x_cfp.tif\"\n",
    "filename = \"bsub_100x_cfp.tif\"\n",
    "with urllib.request.urlopen(url) as response, open(filename, \"wb\") as out_file:\n",
    "    data = response.read()  # a `bytes` object\n",
    "    out_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_cfp = skimage.io.imread(\"bsub_100x_cfp.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove noise\n",
    "- segment the bacteria\n",
    "- plot a histogram of their area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imview(im_cfp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : segmentations des cellules sur l'image des joints\n",
    "Voir la partie \"Start Implementation\" pour mes réponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_joints = skimage.io.imread(\"grains_crop.png\")\n",
    "imview(im_joints)\n",
    "## Denoise the image by Non-Local-Means\n",
    "from skimage import restoration\n",
    "\n",
    "im_denoised = restoration.denoise_nl_means(im_joints, h=0.05)\n",
    "imview(im_denoised)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will not work well. Let's try classical contour detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "\n",
    "edges = feature.canny(im_denoised, sigma=0.2, low_threshold=0.07, high_threshold=0.18)\n",
    "plt.imshow(im_denoised, cmap=\"gray\")\n",
    "plt.contour(edges)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better but not satisfying\n",
    "\n",
    "### Trying a semi-automated method (the interactive part does not in a notebook !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im_denoised, cmap=\"gray\")\n",
    "\n",
    "## you will need to try this outside of a notebook, using the Ipython console version\n",
    "## click_markers = plt.ginput(n=-1, timeout=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.load(\"indices_markers.npy\").T\n",
    "plt.imshow(im_denoised, cmap=\"gray\")\n",
    "plt.plot(y, x, \"or\", ms=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "\n",
    "markers = np.zeros(im_denoised.shape, dtype=np.int32)\n",
    "markers[x.astype(np.int32), y.astype(np.int32)] = np.arange(len(x)) + 1\n",
    "markers = morphology.dilation(markers, morphology.disk(7))\n",
    "# plot them\n",
    "# plt.imshow(im_denoised, cmap='gray')\n",
    "plt.imshow(markers, cmap=\"jet\", alpha=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is different but somewhat similar. Most grain boundaries are well segmented but some are not.\n",
    "\n",
    "We can try a similar optimisation algorithm for contour placement that is a bit more forgiving to weak gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct a smaller sample of labels, because the RW segmentation is linear in the number of labels.\n",
    "## The colors are such that no two neighboring labels have the same color (i.e like in the 4-colour theorem)\n",
    "import sklearn\n",
    "\n",
    "# Graph of nearest neighbors (15 nearest neighbors)\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "mat = kneighbors_graph(np.array([x, y]).T, 15)\n",
    "\n",
    "# Color the graph using a small number of colors\n",
    "!pip install pyamg\n",
    "from pyamg.graph import vertex_coloring\n",
    "\n",
    "colors = vertex_coloring(mat)\n",
    "print(\"Number of colors = \", colors.max(), \"; reduced from \", len(x))\n",
    "\n",
    "# Array of markers\n",
    "markers_rw = np.zeros(im_denoised.shape, dtype=np.int32)\n",
    "markers_rw[x.astype(np.int32), y.astype(np.int32)] = colors + 1\n",
    "markers_rw = morphology.dilation(markers_rw, morphology.disk(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imview(markers_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the segmentation\n",
    "\n",
    "from skimage import segmentation\n",
    "\n",
    "## This imports an adaptive multigrid version of the linear Conjugate Gradient algorithm\n",
    "## it is about 4x faster than the default version\n",
    "import pyamg\n",
    "\n",
    "labels_rw = segmentation.random_walker(\n",
    "    im_denoised, markers_rw, beta=25000, mode=\"cg_mg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "\n",
    "plt.imshow(\n",
    "    color.label2rgb(labels_rw, im_denoised, alpha=0.2)\n",
    ")  ## blends the label and denoised image\n",
    "plt.plot(y, x, \"ok\", ms=2)  ## plots the dots in black\n",
    "ax = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation\n",
    "\n",
    "## This imports an adaptive multigrid version of the linear Conjugate Gradient algorithm\n",
    "## it is about 4x faster than the default version\n",
    "import pyamg\n",
    "\n",
    "labels_rw = segmentation.random_walker(\n",
    "    im_denoised, markers_rw, beta=25000, mode=\"cg_mg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_labels = color.label2rgb(labels_rw, im_denoised, alpha=0.2)\n",
    "plt.imshow(color_labels)  ## blends the label and denoised image\n",
    "# plt.plot(y, x, 'ok', ms=2) ## plots the dots in black\n",
    "ax = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label(labels_rw, x, y, im_denoised, title=\"\"):\n",
    "    plt.imshow(\n",
    "        color.label2rgb(labels_rw, im_denoised, alpha=0.2)\n",
    "    )  ## blends the label and denoised image\n",
    "    plt.plot(y, x, \"ok\", ms=2)  ## plots the dots in black\n",
    "    ax = plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "plot_label(labels_rw, x, y, im_denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_focus = im_denoised[:300, :300]\n",
    "im_focus.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Implementation : Exercise 3 \n",
    "We first load powerwatershed to compare our results,\n",
    "then we will use random walkers to compare it with  power watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2 Watershed segmentation with Powerwatershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save the PGM to run watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save markers as seed.pgm\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def save_pgm(filename, image_array):\n",
    "    img = Image.fromarray(image_array)\n",
    "    img.save(filename, format=\"PPM\")  # PGM is a subset of PPM\n",
    "\n",
    "\n",
    "save_pgm(\"seeds.pgm\", markers)\n",
    "markers = io.imread(\"seeds.pgm\")\n",
    "imview(markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "# Function to view a single image\n",
    "def imview(image, cmap=\"gray\", interpolation=\"nearest\", figsize=(6, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image, cmap=cmap, interpolation=interpolation)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Assuming im_denoised is your grayscale image\n",
    "# Convert the grayscale image to a 3-channel RGB image\n",
    "im_denoised_rgb = np.stack((im_denoised,) * 3, axis=-1)\n",
    "\n",
    "# Save im_denoised as PPM format\n",
    "path_out = \"input_img.ppm\"\n",
    "im = Image.fromarray((im_denoised_rgb * 255).astype(np.uint8))\n",
    "im.save(path_out, format=\"PPM\")\n",
    "\n",
    "# Load the saved image\n",
    "im = io.imread(path_out)\n",
    "\n",
    "# Display both images\n",
    "im = np.array(im)\n",
    "im = im.astype(np.float32) / 255.0  # Convert back to 0-1 range\n",
    "imview(im, cmap=\"gray\")\n",
    "imview(im_denoised, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the output of the algorithm\n",
    "mask = \"/raid/home/bournez_pie/mva_geom/mva_geom_24/3M/TP2/PW_1.0.1/mask.pgm\"\n",
    "# imview(io.imread(mask))\n",
    "# add the markers to the mask\n",
    "from skimage import color\n",
    "\n",
    "mask = io.imread(mask)\n",
    "\n",
    "# display it\n",
    "imview(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of Watershed Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  display the overlay image\n",
    "# the operation to do is ./powerwatsegm.exe -a 2 -i images/2D/input_img.ppm -m images/2D/seeds.pgm\n",
    "overlay = \"/raid/home/bournez_pie/mva_geom/mva_geom_24/3M/TP2/PW_1.0.1/overlay.ppm\"\n",
    "# imview(io.imread(overlay))\n",
    "# add the markers to the overlay\n",
    "from skimage import color\n",
    "\n",
    "overlay = io.imread(overlay)\n",
    "print(\"initial\", overlay.shape)\n",
    "print(\"the color\", overlay.shape)\n",
    "overlay[markers > 0] = [255, 0, 0]\n",
    "# display it\n",
    "imview(overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1 Limite du Random walker vers la LPE puissance\n",
    "Une fois qu'on a calculé Power Watershed, on va faire augmeter le coefficient beta dans le random walker pour retrouver les résultats de la première partie. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, we do the hard computation of the random walker\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import segmentation, color\n",
    "\n",
    "# Define different power values for comparison\n",
    "power_values = [10**k for k in range(0, 10)]\n",
    "# fig, axes = plt.subplots(1, len(power_values), figsize=(15, 5))\n",
    "list_label = []\n",
    "for i, power in enumerate(power_values):\n",
    "    # Perform segmentation using the current power value\n",
    "    labels_rw = segmentation.random_walker(\n",
    "        im_denoised, markers_rw, beta=power, mode=\"cg_mg\"\n",
    "    )\n",
    "    list_label.append(labels_rw)\n",
    "    # plot_label(labels_rw,x,y,im_denoised,title=f\"Power = {power}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "im_focus = im_denoised[:300, :300]\n",
    "height, width = im_focus.shape[:2]  # Get image dimensions\n",
    "# Filter points inside the image\n",
    "result = []\n",
    "for i in range(len(x)):\n",
    "    if 0 <= x[i] < height and 0 <= y[i] < width:\n",
    "        result.append((x[i], y[i]))\n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We plot here the different results\n",
    "\n",
    "for i, power in enumerate(power_values[:8]):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "\n",
    "    # first sublplot, plot the image with the power\n",
    "    ax = axes[0]\n",
    "    labels_rw = list_label[i]\n",
    "    # plot the label\n",
    "    ax.imshow(\n",
    "        color.label2rgb(labels_rw, im_denoised, alpha=0.2)\n",
    "    )  ## blends the label and denoised image\n",
    "    ax.plot(y, x, \"ok\", ms=2)  ## plots the dots in black\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Random Walkers with beta = {power}\")\n",
    "    # second subplot, plot the histogram\n",
    "    ax = axes[1]\n",
    "    ax.imshow(\n",
    "        color.label2rgb(mask, im_denoised, alpha=0.2)\n",
    "    )  ## blends the label and denoised image\n",
    "    ax.set_title(f\" Power watershed output\")\n",
    "    ax.plot(y, x, \"ok\", ms=2)  ## plots the dots in black\n",
    "    # first sublplot, plot the image with the power\n",
    "    ax = axes[2]\n",
    "    ax.imshow(\n",
    "        color.label2rgb(mask[:300, :300], im_focus, alpha=0.2)\n",
    "    )  ## blends the label and denoised image\n",
    "    # ax.plot(y,x,\"ok\",ms=2)\n",
    "    # only plot y x that are inside those value\n",
    "    ax.plot(result[:, 1], result[:, 0], \"or\", ms=4)\n",
    "    ax.set_title(f\" Power watershed output zoomed\")\n",
    "    # first sublplot, plot the image with the power\n",
    "    ax = axes[3]\n",
    "    labels_rw = list_label[i]\n",
    "    # plot the label\n",
    "    ax.imshow(\n",
    "        color.label2rgb(labels_rw[:300, :300], im_focus, alpha=0.2)\n",
    "    )  ## blends the label and denoised image\n",
    "    ax.set_title(f\"Random walker zoomed with beta = {power}\")\n",
    "    # color_labels = color.label2rgb(labels_rw, im_denoised,alpha=0.2)\n",
    "    ax.plot(result[:, 1], result[:, 0], \"or\", ms=4)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    # plot_label(mask,x,y,im_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour des betas <1000, le random walker propose des solutions différent de power Watershed.  \n",
    "Pour des betas entre 1000 et 10000 on remarque que sur les zones zoomés on a une ressemblance entre les deux algorithmes. Pour des betas plus grand, l'algorithme propose des solutions différentes à Power Watershed. \n",
    "\n",
    "On retrouve bien que lorsqye beta tend vers plus l'infini, la solution trouvé par le random walkers converge vers Power Watershed\n",
    "\n",
    "Pour les trop grandes valeurs,  les algorithmes divergent probablement dû à des instabilités numériques. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---- END OF EXERCISE 3 -----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "\n",
    "def trim_close_points(points, distance=1):\n",
    "    \"\"\"\n",
    "    Greedy method to remove some points so that\n",
    "    all points are separated by a distance greater\n",
    "    than ``distance``.\n",
    "\n",
    "    points : array of shape (2, n_points)\n",
    "        Coordinates of 2-D points\n",
    "\n",
    "    distance : float\n",
    "        Minimal distance between points\n",
    "    \"\"\"\n",
    "    x, y = points\n",
    "    tree = spatial.KDTree(np.array([x, y]).T)\n",
    "    pairs = tree.query_pairs(distance)\n",
    "    remove_indices = []\n",
    "    for pair in pairs:\n",
    "        if pair[0] in remove_indices:\n",
    "            continue\n",
    "        if pair[1] in remove_indices:\n",
    "            continue\n",
    "        else:\n",
    "            remove_indices.append(pair[1])\n",
    "    keep_indices = np.setdiff1d(np.arange(len(x)), remove_indices)\n",
    "    return np.array([x[keep_indices], y[keep_indices]])\n",
    "\n",
    "\n",
    "# Check result on simple example\n",
    "x, y = np.random.random((2, 1000))\n",
    "xk, yk = trim_close_points((x, y), 0.1)\n",
    "plt.plot(x, y, \"o\")\n",
    "plt.plot(xk, yk, \"or\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple random walkers\n",
    "\n",
    "Now we perform a large number of random walker segmentations, using different sets of markers. To reduce the computing time, we use a downsampled array here. However, executing the cell below still took 50 minutes on my machine! If you would like to reproduce the results here, you can start from a smaller number of realizations, like 50.\n",
    "\n",
    "Also, the method of computing segmentations from different sets of markers belongs to the class of embarassingly parallel problems, so that it is easy to parallelize this part. For this purpose, you can use the joblib library, that provide a helper function Parallel for simple parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "n_instances = 20\n",
    "n_markers = 1000\n",
    "segmentations = []\n",
    "t1 = time()\n",
    "for instance in range(n_instances):\n",
    "    # Random markers\n",
    "    x, y = np.random.random((2, n_markers))\n",
    "    x *= im_denoised.shape[0]\n",
    "    y *= im_denoised.shape[1]\n",
    "    # Remove points too close to each other\n",
    "    xk, yk = trim_close_points((x, y), 20)\n",
    "    mat = kneighbors_graph(np.array([xk, yk]).T, 12)\n",
    "    colors = vertex_coloring(mat)\n",
    "    # Array of markers\n",
    "    markers_rw = np.zeros(im_denoised.shape, dtype=np.int32)\n",
    "    markers_rw[xk.astype(np.int32), yk.astype(np.int32)] = colors + 1\n",
    "    markers_rw = morphology.dilation(markers_rw, morphology.disk(3))\n",
    "    # Segmentation\n",
    "    labels_rw = segmentation.random_walker(\n",
    "        im_denoised[::2, ::2], markers_rw[::2, ::2], beta=25000, mode=\"cg_mg\"\n",
    "    )\n",
    "    segmentations.append(labels_rw)\n",
    "    print(\".\", end=\"\")\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentations = np.array(segmentations)\n",
    "boundaries = np.zeros_like(im_denoised[::2, ::2])\n",
    "for seg in segmentations:\n",
    "    boundaries += segmentation.find_boundaries(seg, connectivity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(boundaries, cmap=\"gist_heat\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis_thresholding(im, v_low, v_high):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    im : 2-D array\n",
    "\n",
    "    v_low : float\n",
    "        low threshold\n",
    "\n",
    "    v_high : float\n",
    "        high threshold\n",
    "    \"\"\"\n",
    "    mask_low = im > v_low\n",
    "    mask_high = im > v_high\n",
    "    # Connected components of mask_low\n",
    "    labels_low = measure.label(mask_low, background=0) + 1\n",
    "    count = labels_low.max()\n",
    "    # Check if connected components contain pixels from mask_high\n",
    "    sums = ndimage.sum(mask_high, labels_low, np.arange(count + 1))\n",
    "    good_label = np.zeros((count + 1,), bool)\n",
    "    good_label[1:] = sums[1:] > 0\n",
    "    output_mask = good_label[labels_low]\n",
    "    return output_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure, color\n",
    "\n",
    "\n",
    "def color_segmentation(regions, n_neighbors=25):\n",
    "    \"\"\"\n",
    "    Reduce the number of labels in a label image to make\n",
    "    visualization easier.\n",
    "    \"\"\"\n",
    "    count = regions.max()\n",
    "    centers = ndimage.center_of_mass(\n",
    "        regions + 2, regions, index=np.arange(1, count + 1)\n",
    "    )\n",
    "    centers = np.array(centers)\n",
    "    mat = kneighbors_graph(np.array(centers), n_neighbors)\n",
    "    colors = vertex_coloring(mat)\n",
    "    colors = np.concatenate(([0], colors))\n",
    "    return colors[regions]\n",
    "\n",
    "\n",
    "def plot_colors(val_low, val_high):\n",
    "    \"\"\"\n",
    "    Plot result of segmentation superimposed on original image,\n",
    "    and plot original image as well.\n",
    "    \"\"\"\n",
    "    seg = hysteresis_thresholding(boundaries, val_low, val_high)\n",
    "    regions = measure.label(np.logical_not(seg), background=0, connectivity=1)\n",
    "    color_regions = color_segmentation(regions)\n",
    "    colors = [\n",
    "        plt.cm.Spectral(val) for val in np.linspace(0, 1, color_regions.max() + 1)\n",
    "    ]\n",
    "    image_label_overlay = color.label2rgb(\n",
    "        color_regions, im_denoised[::2, ::2], colors=colors\n",
    "    )\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(image_label_overlay)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(im_denoised, cmap=\"gray\")\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = plot_colors(0.3 * n_instances, 0.55 * n_instances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check the effect of thresholding parameters, we write helper functions that produce meaningful visualizations of the segmentation.\n",
    "\n",
    "Segmented regions are extracted as connected components in an image where background pixels are the boundaries determined from hysteresis thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure, color\n",
    "\n",
    "\n",
    "def color_segmentation(regions, n_neighbors=25):\n",
    "    \"\"\"\n",
    "    Reduce the number of labels in a label image to make\n",
    "    visualization easier.\n",
    "    \"\"\"\n",
    "    count = regions.max()\n",
    "    centers = ndimage.center_of_mass(\n",
    "        regions + 2, regions, index=np.arange(1, count + 1)\n",
    "    )\n",
    "    centers = np.array(centers)\n",
    "    mat = kneighbors_graph(np.array(centers), n_neighbors)\n",
    "    colors = vertex_coloring(mat)\n",
    "    colors = np.concatenate(([0], colors))\n",
    "    return colors[regions]\n",
    "\n",
    "\n",
    "def plot_colors(val_low, val_high):\n",
    "    \"\"\"\n",
    "    Plot result of segmentation superimposed on original image,\n",
    "    and plot original image as well.\n",
    "    \"\"\"\n",
    "    seg = hysteresis_thresholding(boundaries, val_low, val_high)\n",
    "    regions = measure.label(np.logical_not(seg), background=0, connectivity=1)\n",
    "    color_regions = color_segmentation(regions)\n",
    "    colors = [\n",
    "        plt.cm.Spectral(val) for val in np.linspace(0, 1, color_regions.max() + 1)\n",
    "    ]\n",
    "    image_label_overlay = color.label2rgb(\n",
    "        color_regions, im_denoised[::2, ::2], colors=colors\n",
    "    )\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(image_label_overlay)\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(im_denoised, cmap=\"gray\")\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = plot_colors(0.3 * n_instances, 0.55 * n_instances)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that a good pair of thresholds has been found, it is possible to clean the segmentation by removing small connected components. We relabel labels so that there are no missing labels.\n",
    "\n",
    "Below, we use a visualization trick so that neighboring regions have different colors: we shuffle labels using np.random.permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_clean = morphology.remove_small_objects(regions + 1, min_size=60)\n",
    "regions_clean, _, _ = segmentation.relabel_sequential(regions_clean)\n",
    "plt.imshow(\n",
    "    np.random.permutation(regions_clean.max() + 1)[regions_clean], cmap=\"Spectral\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to finish the segmentation and to label pixels that have been labeled as boundaries (some of them being \"real boundaries\", other not), several possibilities exist, such as using mathematical morphology operations. Here, we'll continue using the random walker to attribute the remaining unknown pixels. We could use the coloring trick again, but since the number of pixels to be determined is small, it is not a big deal not to use it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_segmentation = segmentation.random_walker(\n",
    "    im_denoised[::2, ::2], regions_clean, beta=25000, mode=\"cg_mg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    color.label2rgb(\n",
    "        final_segmentation,\n",
    "        im_denoised[::2, ::2],\n",
    "        colors=plt.cm.Spectral(np.linspace(0, 1, 40)),\n",
    "    )\n",
    ")\n",
    "ax = plt.axis(\"off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use different colors if we want to make sure that some pairs of neighboring grains have different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    np.random.permutation(final_segmentation.max() + 1)[final_segmentation],\n",
    "    cmap=\"Spectral\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was therefore possible to reach a satisfying segmentation in a more automatic way. Depending on your image, it is possible that segmentation from random markers using the watershed algorithm can also result in a good segmentation, in which you can save a lot of time.\n",
    "\n",
    "Note that it would be possible to improve an automatic segmentation by clicking on a few regions that would not have been segmented correctly, and applying the random walker to these regions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
